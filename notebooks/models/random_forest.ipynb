{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "============================================================================================\n",
    "\n",
    "# RandomForest\n",
    "\n",
    "============================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athenaeum_authors.csv\n",
      "athenaeum_authors_preview.csv\n",
      "athenaeum_painting_filtered.csv\n",
      "athenaeum_painting_movement.csv\n",
      "athenaeum_painting_movement_test.csv\n",
      "athenaeum_painting_movement_train.csv\n",
      "athenaeum_paintings.csv\n",
      "athenaeum_paintings_sizes.csv\n",
      "color_hist_kmeans_206552.csv\n",
      "color_histograms.csv\n",
      "color_hist_size_206552.csv\n",
      "complete_data.csv\n",
      "extra_tree_com.csv\n",
      "grad_boost_com.csv\n",
      "images\n",
      "images_athenaeum\n",
      "images_sizes_2325.csv\n",
      "kmeans_centers.csv\n",
      "kmeans.png\n",
      "kmeans_tsne.png\n",
      "knn_com.csv\n",
      "model_accuracy.csv\n",
      "movement_hist_test.csv\n",
      "movement_hist_train.csv\n",
      "nbc_com.csv\n",
      "net_predicted.csv\n",
      "painter_info_clean.csv\n",
      "painting_info_clean.csv\n",
      "pca20_kmeans_test.csv\n",
      "pca20_kmeans_train.csv\n",
      "resized_200\n",
      "rf_com.csv\n",
      "test_author200.csv\n",
      "test_data.csv\n",
      "test_hist_author_knn.csv\n",
      "test_hist_author_rf.csv\n",
      "train_author200.csv\n",
      "train_data.csv\n",
      "train_hist_author_knn.csv\n",
      "train_hist_author_rf.csv\n",
      "xgb_com.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from src import fns_models as fns\n",
    "\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"data\"]).decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The size of train histogram for Random Forest(49890, 35)\n",
      "[INFO] The size of test histogram for Random Forest(12473, 35)\n",
      "24      1369\n",
      "1793    1338\n",
      "368     1335\n",
      "Name: author_id, dtype: int64\n",
      "[trian above] ==================================================[test below]\n",
      "24      342\n",
      "1793    335\n",
      "368     334\n",
      "Name: author_id, dtype: int64\n",
      "(4042,)\n",
      "(4042, 35)\n"
     ]
    }
   ],
   "source": [
    "train, train_labels, test, test_labels = fns.get_top_author(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "================================================================================================================\n",
    "\n",
    "# Bayesian Optimization + Random Forest\n",
    "\n",
    "[bayesian-optimization](https://github.com/fmfn/BayesianOptimization/blob/master/bayes_opt/bayesian_optimization.py)\n",
    "\n",
    "================================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rf_evaluate(max_features, max_depth, n_estimators):\n",
    "    \n",
    "    random.seed(2017)\n",
    "#     params['max_features'] = int(max_features)\n",
    "#     params['max_depth'] = int(max_depth)\n",
    "#     params['n_estimators'] = int(n_estimators)\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_jobs = 4, n_estimators=int(n_estimators), oob_score=True,\n",
    "                                max_depth = int(max_depth), max_features = int(max_features))\n",
    "    #scores = cross_val_score(rfc, X=train, y = train_labels, cv=5, n_jobs = 2)\n",
    "    \n",
    "    # The mean score and the 95% confidence interval of the score estimate are hence given by:\n",
    "    #print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    #return scores.mean()\n",
    "    rfc.fit(train, train_labels)\n",
    "    return rfc.oob_score_\n",
    "\n",
    "def rf_pca_evaluate(max_features,\n",
    "                    max_depth,\n",
    "                    n_estimators):\n",
    "    \n",
    "    random.seed(2017)\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_jobs = 4, n_estimators=int(n_estimators), oob_score=True,\n",
    "                                max_depth = int(max_depth), max_features = int(max_features))\n",
    "    \n",
    "    rfc.fit(pca_transformed, train_labels)\n",
    "    return rfc.oob_score_\n",
    "\n",
    "def rf_bo(rf_fnc=rf_evaluate):\n",
    "    start_time = time.time()\n",
    "    num_iter = 25\n",
    "    init_points = 5\n",
    "    random_state = 2017\n",
    "    # params = {\n",
    "    #     #'eta': 0.1,\n",
    "    #     #'silent': 1,\n",
    "    #     'eval_metric': 'mae',\n",
    "    #     'verbose_eval': True,\n",
    "    #     #'seed': random_state\n",
    "    # }\n",
    "\n",
    "    rfBO = BayesianOptimization(rf_fnc, {'max_features': (5, 7),\n",
    "                                             'max_depth': (2, 10),\n",
    "                                             'n_estimators': (100, 720)})\n",
    "\n",
    "    rfBO.maximize(init_points=init_points, n_iter=num_iter)\n",
    "    print('-' * 53)\n",
    "    print 'Costed time: \\n%f' % (time.time() - start_time)\n",
    "    \n",
    "    print \"Bayesian Optimization Best Score: %f\" % rfBO.res['max']['max_val']\n",
    "\n",
    "    print \"Bayesian Optimization Best Parameters: %s\" % str(rfBO.res['max']['max_params'])\n",
    "    \n",
    "    print (rfBO.res['max'])\n",
    "    \n",
    "#     fns.plot_bo(rf_fnc, rfBO)\n",
    "\n",
    "#     print \"Bayesian Optimization  Parameters: %s\" % str(rfBO.res['all'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   max_features |   n_estimators | \n",
      "    1 | 00m06s | \u001b[35m   0.67392\u001b[0m | \u001b[32m     7.9940\u001b[0m | \u001b[32m        5.5696\u001b[0m | \u001b[32m      477.0931\u001b[0m | \n",
      "    2 | 00m07s | \u001b[35m   0.68728\u001b[0m | \u001b[32m     9.7176\u001b[0m | \u001b[32m        6.3575\u001b[0m | \u001b[32m      499.4903\u001b[0m | \n",
      "    3 | 00m05s |    0.66155 |      6.8852 |         6.6994 |       390.4199 | \n",
      "    4 | 00m04s |    0.64448 |      5.6782 |         5.9174 |       358.4043 | \n",
      "    5 | 00m02s |    0.66353 |      6.8468 |         6.8560 |       176.9217 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   max_features |   n_estimators | \n",
      "    6 | 00m21s |    0.59476 |      2.1977 |         6.7143 |       719.9367 | \n",
      "    7 | 00m08s |    0.68530 |      9.3571 |         6.9973 |       100.0350 | \n",
      "    8 | 00m17s | \u001b[35m   0.69050\u001b[0m | \u001b[32m     9.9859\u001b[0m | \u001b[32m        6.7287\u001b[0m | \u001b[32m      589.7670\u001b[0m | \n",
      "    9 | 00m15s |    0.59624 |      2.0519 |         6.8887 |       545.9926 | \n",
      "   10 | 00m18s | \u001b[35m   0.69099\u001b[0m | \u001b[32m    10.0000\u001b[0m | \u001b[32m        5.0000\u001b[0m | \u001b[32m      650.5581\u001b[0m | \n",
      "   11 | 00m12s | \u001b[35m   0.69619\u001b[0m | \u001b[32m    10.0000\u001b[0m | \u001b[32m        7.0000\u001b[0m | \u001b[32m      261.8496\u001b[0m | \n",
      "   12 | 00m11s |    0.67590 |      9.9934 |         5.0287 |       224.2714 | \n",
      "   13 | 00m12s |    0.68803 |      9.9772 |         5.0981 |       300.7707 | \n",
      "   14 | 00m18s |    0.68827 |      9.9452 |         6.9612 |       617.8909 | \n",
      "   15 | 00m09s |    0.68530 |     10.0000 |         5.0000 |       136.1448 | \n",
      "   16 | 00m13s |    0.68877 |      9.9883 |         6.6737 |       432.8401 | \n",
      "   17 | 00m19s |    0.68877 |      9.9659 |         6.7880 |       675.1810 | \n",
      "   18 | 00m13s |    0.69124 |      9.8874 |         5.0418 |       278.4082 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  1.48832769e-05]), 'nit': 5, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 00m17s | \u001b[35m   0.69891\u001b[0m | \u001b[32m    10.0000\u001b[0m | \u001b[32m        7.0000\u001b[0m | \u001b[32m      456.6774\u001b[0m | \n",
      "   20 | 00m15s |    0.68654 |      9.9857 |         6.9466 |       322.6136 | \n",
      "   21 | 00m18s |    0.69767 |     10.0000 |         7.0000 |       281.0554 | \n",
      "   22 | 00m15s |    0.68629 |      9.8626 |         6.9470 |       117.6207 | \n",
      "   23 | 00m27s | \u001b[35m   0.70089\u001b[0m | \u001b[32m    10.0000\u001b[0m | \u001b[32m        7.0000\u001b[0m | \u001b[32m      654.0983\u001b[0m | \n",
      "   24 | 00m21s |    0.68481 |      9.8720 |         6.9704 |       661.1967 | \n",
      "   25 | 00m11s |    0.59574 |      2.0350 |         7.0000 |       127.8315 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  2.73755060e-05]), 'nit': 5, 'funcalls': 55}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 00m22s |    0.69767 |     10.0000 |         7.0000 |       639.1012 | \n",
      "   27 | 00m13s |    0.69050 |      9.9746 |         6.9016 |       196.8099 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 0.00010053]), 'nit': 6, 'funcalls': 56}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 00m13s |    0.68135 |      9.9786 |         6.7980 |       156.8125 | \n",
      "   29 | 00m21s |    0.68803 |      9.9550 |         6.9078 |       695.8416 | \n",
      "   30 | 00m18s |    0.68382 |      9.9956 |         6.9743 |       373.5136 | \n",
      "-----------------------------------------------------\n",
      "Costed time: \n",
      "436.890886\n",
      "Bayesian Optimization Best Score: 0.700891\n",
      "Bayesian Optimization Best Parameters: {'max_features': 7.0, 'n_estimators': 654.09827233352632, 'max_depth': 10.0}\n",
      "{'max_val': 0.70089064819396341, 'max_params': {'max_features': 7.0, 'n_estimators': 654.09827233352632, 'max_depth': 10.0}}\n"
     ]
    }
   ],
   "source": [
    "# Run BO for color histogram\n",
    "rf_bo(rf_evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of best Random Forest model on train: 0.737258782781\n",
      "Accuracy of best Random Forest model on test: 0.686449060336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  24, 1793, 1793, ..., 1793,   24, 1793])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the best params from BO results then predict \n",
    "best_estimators = 654\n",
    "best_max_depth = 6\n",
    "best_max_features = 7\n",
    "best_rfc = RandomForestClassifier(n_jobs = 4, n_estimators=best_estimators, oob_score=False,\n",
    "                                max_depth = best_max_depth, max_features = best_max_features)\n",
    "\n",
    "best_rfc.fit(train, train_labels)\n",
    "\n",
    "# accuracy of trianing dataset\n",
    "print \"Accuracy of best Random Forest model on train: %s\" % str(best_rfc.score(train, train_labels))\n",
    "\n",
    "# accuracy of testing dataset\n",
    "print \"Accuracy of best Random Forest model on test: %s\" % str(best_rfc.score(test, test_labels))\n",
    "\n",
    "\n",
    "# use the best params to predict\n",
    "rfc_true, rfc_pred = test_labels, best_rfc.predict(test)\n",
    "rfc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=6, max_features=7, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=654, n_jobs=4, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.686449060336\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'random_forest.sav'\n",
    "pickle.dump(best_rfc, open(filename, 'wb'))\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_rfc = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_rfc.score(test, test_labels)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>rf_pred</th>\n",
       "      <th>rf_res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>24</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>24</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>24</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9715</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9716</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9718</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9720</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9726</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9727</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9729</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9730</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9731</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9732</th>\n",
       "      <td>24</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9734</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9735</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9746</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9749</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9752</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9753</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9756</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9757</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9758</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9759</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1011 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual  rf_pred rf_res\n",
       "33        24       24   True\n",
       "34      1793     1793   True\n",
       "35      1793     1793   True\n",
       "37      1793     1793   True\n",
       "101     1793     1793   True\n",
       "102     1793     1793   True\n",
       "105     1793     1793   True\n",
       "217     1793       24  False\n",
       "261     1793     1793   True\n",
       "295     1793     1793   True\n",
       "354     1793     1793   True\n",
       "355     1793     1793   True\n",
       "399     1793     1793   True\n",
       "474     1793     1793   True\n",
       "507     1793     1793   True\n",
       "545     1793     1793   True\n",
       "554       24       24   True\n",
       "604       24       24   True\n",
       "607       24      368  False\n",
       "608       24       24   True\n",
       "662       24     1793  False\n",
       "686     1793     1793   True\n",
       "710     1793     1793   True\n",
       "860       24      368  False\n",
       "861       24      368  False\n",
       "862       24     1793  False\n",
       "863       24       24   True\n",
       "864       24       24   True\n",
       "865       24       24   True\n",
       "866       24       24   True\n",
       "...      ...      ...    ...\n",
       "9704    1793     1793   True\n",
       "9715    1793     1793   True\n",
       "9716    1793     1793   True\n",
       "9718    1793      368  False\n",
       "9719    1793       24  False\n",
       "9720    1793     1793   True\n",
       "9724    1793     1793   True\n",
       "9726    1793     1793   True\n",
       "9727    1793     1793   True\n",
       "9729    1793      368  False\n",
       "9730    1793     1793   True\n",
       "9731    1793       24  False\n",
       "9732      24      368  False\n",
       "9734      24       24   True\n",
       "9735    1793     1793   True\n",
       "9739      24       24   True\n",
       "9740      24       24   True\n",
       "9744      24     1793  False\n",
       "9746      24       24   True\n",
       "9749      24       24   True\n",
       "9750      24       24   True\n",
       "9751      24       24   True\n",
       "9752      24       24   True\n",
       "9753      24       24   True\n",
       "9754      24       24   True\n",
       "9755      24       24   True\n",
       "9756      24       24   True\n",
       "9757      24     1793  False\n",
       "9758      24       24   True\n",
       "9759      24     1793  False\n",
       "\n",
       "[1011 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_test_df = fns.result_table(rfc_true, rfc_pred)\n",
    "rf_test_df = rf_test_df.rename(index=str, columns={'predictions': 'rf_pred', 'results': 'rf_res'})\n",
    "rf_test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">rf_res</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_pred</th>\n",
       "      <th>24</th>\n",
       "      <th>368</th>\n",
       "      <th>1793</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>234</td>\n",
       "      <td>48</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>39</td>\n",
       "      <td>224</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>38</td>\n",
       "      <td>61</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rf_res          \n",
       "rf_pred   24   368  1793\n",
       "actual                  \n",
       "24         234   48   60\n",
       "368         39  224   71\n",
       "1793        38   61  236"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_test_df.groupby(['actual', 'rf_pred']).aggregate({'rf_res': 'count'}).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "================================================================================================================\n",
    "\n",
    "# PCA\n",
    "\n",
    "================================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Get 15 principal components\n",
    "pca = PCA(n_components=20)\n",
    "pca.fit(train)\n",
    "pca_transformed = pca.transform(train)\n",
    "\n",
    "pca_transformed_test = pca.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99703072537056514"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAH4CAYAAAD6lMGqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f46001da710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "plt.plot(pca.explained_variance_ratio_, )\n",
    "plt.title(\"Scree Plot: 15 Principal Components\")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"% of Explained Variance\")\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "======================================================================================================\n",
    "\n",
    "# Random Forest + PCA\n",
    "\n",
    "======================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   max_features |   n_estimators | \n",
      "    1 | 00m04s | \u001b[35m   0.56358\u001b[0m | \u001b[32m     2.6284\u001b[0m | \u001b[32m        6.4277\u001b[0m | \u001b[32m      530.4468\u001b[0m | \n",
      "    2 | 00m06s | \u001b[35m   0.62865\u001b[0m | \u001b[32m     5.9855\u001b[0m | \u001b[32m        6.9211\u001b[0m | \u001b[32m      558.7029\u001b[0m | \n",
      "    3 | 00m05s |    0.58832 |      3.5851 |         5.7812 |       594.1779 | \n",
      "    4 | 00m06s |    0.59401 |      3.9791 |         5.6445 |       588.9019 | \n",
      "    5 | 00m04s | \u001b[35m   0.63013\u001b[0m | \u001b[32m     5.9280\u001b[0m | \u001b[32m        5.7369\u001b[0m | \u001b[32m      322.3853\u001b[0m | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   max_features |   n_estimators | \n",
      "    6 | 00m19s | \u001b[35m   0.66452\u001b[0m | \u001b[32m    10.0000\u001b[0m | \u001b[32m        7.0000\u001b[0m | \u001b[32m      100.0000\u001b[0m | \n",
      "    7 | 00m22s | \u001b[35m   0.66576\u001b[0m | \u001b[32m    10.0000\u001b[0m | \u001b[32m        7.0000\u001b[0m | \u001b[32m      720.0000\u001b[0m | \n",
      "    8 | 00m11s |    0.66329 |      9.7643 |         6.9618 |       206.3093 | \n",
      "    9 | 00m14s |    0.66230 |      9.9508 |         6.9063 |       402.5351 | \n",
      "   10 | 00m08s |    0.56408 |      2.0179 |         5.5760 |       150.1354 | \n",
      "   11 | 00m12s |    0.66477 |      9.9179 |         6.6891 |       260.0988 | \n",
      "   12 | 00m18s | \u001b[35m   0.67219\u001b[0m | \u001b[32m     9.9510\u001b[0m | \u001b[32m        6.8468\u001b[0m | \u001b[32m      674.1693\u001b[0m | \n",
      "   13 | 00m14s |    0.66502 |      9.9072 |         6.8666 |       366.7500 | \n",
      "   14 | 00m15s |    0.66749 |      9.9940 |         6.9664 |       447.9864 | \n",
      "   15 | 00m11s |    0.66997 |      9.9504 |         5.1304 |       231.8717 | \n",
      "   16 | 00m18s |    0.66576 |      9.9891 |         5.2606 |       697.9774 | \n",
      "   17 | 00m19s |    0.66205 |      9.9973 |         6.6935 |       645.5310 | \n",
      "   18 | 00m14s |    0.66452 |      9.9927 |         6.9834 |       293.4353 | \n",
      "   19 | 00m17s |    0.66873 |      9.9906 |         6.7586 |       427.7723 | \n",
      "   20 | 00m15s |    0.66799 |      9.9790 |         6.9790 |       340.8515 | \n",
      "   21 | 00m14s |    0.66180 |      9.9828 |         6.9739 |       240.0485 | \n",
      "   22 | 00m17s |    0.66947 |     10.0000 |         5.0000 |       470.7071 | \n",
      "   23 | 00m17s |    0.66526 |     10.0000 |         5.0000 |       276.1377 | \n",
      "   24 | 00m21s |    0.66056 |      9.9358 |         5.0326 |       663.2862 | \n",
      "   25 | 00m23s |    0.66650 |     10.0000 |         7.0000 |       488.8521 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -2.89450110e-05]), 'nit': 5, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 | 00m24s |    0.66378 |      9.9164 |         6.6623 |       567.0699 | \n",
      "   27 | 00m20s |    0.66353 |      9.9783 |         5.0921 |       217.3870 | \n",
      "   28 | 00m18s |    0.66329 |      9.9081 |         5.0209 |       185.8774 | \n",
      "   29 | 00m23s |    0.66848 |      9.9996 |         5.2258 |       310.8649 | \n",
      "   30 | 00m29s |    0.66972 |      9.9361 |         6.9127 |       684.3192 | \n",
      "-----------------------------------------------------\n",
      "Costed time: \n",
      "472.395768\n",
      "Bayesian Optimization Best Score: 0.672192\n",
      "Bayesian Optimization Best Parameters: {'max_features': 6.846765029205554, 'n_estimators': 674.16932953229752, 'max_depth': 9.9510146776519939}\n",
      "{'max_val': 0.67219198416625436, 'max_params': {'max_features': 6.846765029205554, 'n_estimators': 674.16932953229752, 'max_depth': 9.9510146776519939}}\n"
     ]
    }
   ],
   "source": [
    "# Run BO for pca of color histogram\n",
    "rf_bo(rf_pca_evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Model on training set:0.724888668976\n",
      "Accuracy of the Model on testing set:0.668644906034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  24, 1793, 1793, ..., 1793,   24, 1793])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the best params from BO results then predict \n",
    "best_pca_estimators = 674\n",
    "best_pca_max_depth = 6\n",
    "best_pca_max_features = 7\n",
    "best_pca_rfc = RandomForestClassifier(n_jobs = 4, n_estimators=best_pca_estimators, oob_score=False,\n",
    "                                max_depth = best_pca_max_depth, max_features = best_pca_max_features)\n",
    "\n",
    "best_pca_rfc.fit(pca_transformed, train_labels)\n",
    "\n",
    "# accuracy for the train set\n",
    "print \"Accuracy of the Model on training set:\" + str(best_pca_rfc.score(pca_transformed,train_labels))\n",
    "\n",
    "# accuracy for the test set\n",
    "print \"Accuracy of the Model on testing set:\" + str(best_pca_rfc.score(pca_transformed_test,test_labels))\n",
    "\n",
    "# use the best params to predict\n",
    "rfc_pac_true, rfc_pca_pred = test_labels, best_pca_rfc.predict(pca_transformed_test)\n",
    "rfc_pca_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668644906034\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'random_forest_pca.sav'\n",
    "pickle.dump(best_pca_rfc, open(filename, 'wb'))\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_rfc_pca = pickle.load(open(filename, 'rb'))\n",
    "result_pca = loaded_rfc_pca.score(pca_transformed_test, test_labels)\n",
    "print(result_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>rf_pca_pred</th>\n",
       "      <th>rf_pca_res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>24</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>24</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9715</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9716</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9718</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9720</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9726</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9727</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9729</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9730</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9731</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9732</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9734</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9735</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9746</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9749</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9752</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9753</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9756</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9757</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9758</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9759</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1011 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual  rf_pca_pred rf_pca_res\n",
       "33        24           24       True\n",
       "34      1793         1793       True\n",
       "35      1793         1793       True\n",
       "37      1793         1793       True\n",
       "101     1793          368      False\n",
       "102     1793         1793       True\n",
       "105     1793         1793       True\n",
       "217     1793           24      False\n",
       "261     1793         1793       True\n",
       "295     1793         1793       True\n",
       "354     1793           24      False\n",
       "355     1793           24      False\n",
       "399     1793         1793       True\n",
       "474     1793         1793       True\n",
       "507     1793         1793       True\n",
       "545     1793         1793       True\n",
       "554       24           24       True\n",
       "604       24         1793      False\n",
       "607       24          368      False\n",
       "608       24         1793      False\n",
       "662       24           24       True\n",
       "686     1793         1793       True\n",
       "710     1793         1793       True\n",
       "860       24          368      False\n",
       "861       24           24       True\n",
       "862       24         1793      False\n",
       "863       24           24       True\n",
       "864       24           24       True\n",
       "865       24           24       True\n",
       "866       24           24       True\n",
       "...      ...          ...        ...\n",
       "9704    1793         1793       True\n",
       "9715    1793          368      False\n",
       "9716    1793          368      False\n",
       "9718    1793           24      False\n",
       "9719    1793          368      False\n",
       "9720    1793         1793       True\n",
       "9724    1793         1793       True\n",
       "9726    1793         1793       True\n",
       "9727    1793         1793       True\n",
       "9729    1793           24      False\n",
       "9730    1793         1793       True\n",
       "9731    1793           24      False\n",
       "9732      24           24       True\n",
       "9734      24           24       True\n",
       "9735    1793         1793       True\n",
       "9739      24           24       True\n",
       "9740      24           24       True\n",
       "9744      24         1793      False\n",
       "9746      24           24       True\n",
       "9749      24           24       True\n",
       "9750      24           24       True\n",
       "9751      24           24       True\n",
       "9752      24           24       True\n",
       "9753      24           24       True\n",
       "9754      24           24       True\n",
       "9755      24           24       True\n",
       "9756      24           24       True\n",
       "9757      24         1793      False\n",
       "9758      24           24       True\n",
       "9759      24         1793      False\n",
       "\n",
       "[1011 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_rf_test_df = fns.result_table(rfc_pac_true, rfc_pca_pred)\n",
    "pca_rf_test_df = pca_rf_test_df.rename(index=str, columns={'predictions': 'rf_pca_pred', 'results': 'rf_pca_res'})\n",
    "pca_rf_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">rf_pca_res</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_pca_pred</th>\n",
       "      <th>24</th>\n",
       "      <th>368</th>\n",
       "      <th>1793</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>229</td>\n",
       "      <td>49</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>42</td>\n",
       "      <td>214</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>45</td>\n",
       "      <td>57</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rf_pca_res          \n",
       "rf_pca_pred       24   368  1793\n",
       "actual                          \n",
       "24                 229   49   64\n",
       "368                 42  214   78\n",
       "1793                45   57  233"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_rf_test_df.groupby(['actual', 'rf_pca_pred']).aggregate({'rf_pca_res': 'count'}).unstack()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>rf_pred</th>\n",
       "      <th>rf_res</th>\n",
       "      <th>rf_pca_pred</th>\n",
       "      <th>rf_pca_res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340715</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340716</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340717</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340718</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340719</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340720</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340721</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340722</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340723</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340724</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340725</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340726</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340727</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340728</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340729</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340730</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340731</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340732</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340733</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340734</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340735</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340736</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340737</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340738</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340739</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340740</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340741</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340742</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340743</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340744</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340745 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        actual  rf_pred rf_res  rf_pca_pred rf_pca_res\n",
       "0           24       24   True           24       True\n",
       "1           24       24   True           24       True\n",
       "2           24       24   True         1793      False\n",
       "3           24       24   True          368      False\n",
       "4           24       24   True         1793      False\n",
       "5           24       24   True           24       True\n",
       "6           24       24   True          368      False\n",
       "7           24       24   True           24       True\n",
       "8           24       24   True         1793      False\n",
       "9           24       24   True           24       True\n",
       "10          24       24   True           24       True\n",
       "11          24       24   True           24       True\n",
       "12          24       24   True           24       True\n",
       "13          24       24   True          368      False\n",
       "14          24       24   True          368      False\n",
       "15          24       24   True           24       True\n",
       "16          24       24   True           24       True\n",
       "17          24       24   True         1793      False\n",
       "18          24       24   True           24       True\n",
       "19          24       24   True         1793      False\n",
       "20          24       24   True           24       True\n",
       "21          24       24   True           24       True\n",
       "22          24       24   True           24       True\n",
       "23          24       24   True         1793      False\n",
       "24          24       24   True          368      False\n",
       "25          24       24   True           24       True\n",
       "26          24       24   True           24       True\n",
       "27          24       24   True           24       True\n",
       "28          24       24   True         1793      False\n",
       "29          24       24   True           24       True\n",
       "...        ...      ...    ...          ...        ...\n",
       "340715     368      368   True          368       True\n",
       "340716     368      368   True          368       True\n",
       "340717     368      368   True          368       True\n",
       "340718     368      368   True          368       True\n",
       "340719     368      368   True          368       True\n",
       "340720     368      368   True         1793      False\n",
       "340721     368      368   True          368       True\n",
       "340722     368      368   True          368       True\n",
       "340723     368      368   True          368       True\n",
       "340724     368      368   True          368       True\n",
       "340725     368      368   True           24      False\n",
       "340726     368      368   True         1793      False\n",
       "340727     368      368   True         1793      False\n",
       "340728     368      368   True          368       True\n",
       "340729     368      368   True          368       True\n",
       "340730     368      368   True         1793      False\n",
       "340731     368      368   True          368       True\n",
       "340732     368      368   True         1793      False\n",
       "340733     368      368   True          368       True\n",
       "340734     368      368   True           24      False\n",
       "340735     368      368   True         1793      False\n",
       "340736     368      368   True         1793      False\n",
       "340737     368      368   True          368       True\n",
       "340738     368      368   True          368       True\n",
       "340739     368      368   True          368       True\n",
       "340740     368      368   True           24      False\n",
       "340741     368      368   True         1793      False\n",
       "340742     368      368   True           24      False\n",
       "340743     368      368   True          368       True\n",
       "340744     368      368   True          368       True\n",
       "\n",
       "[340745 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_com = rf_test_df.merge(pca_rf_test_df, how='inner', on='actual')\n",
    "rf_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rf_com.to_csv('data/rf_com.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Random Forest to predict art movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_top_movement(num_movements = 3):\n",
    "    movement_hist_train = pd.read_csv('data/movement_hist_train.csv')\n",
    "    movement_hist_test = pd.read_csv('data/movement_hist_test.csv')\n",
    "    \n",
    "    print \"[INFO] The size of train histogram for Random Forest\" + str(movement_hist_train.shape)\n",
    "    print \"[INFO] The size of test histogram for Random Forest\" + str(movement_hist_test.shape)\n",
    "\n",
    "    movement_hist_train.iloc[:,3:-1] = movement_hist_train.iloc[:, 3:-1]\\\n",
    "        .apply(lambda x: x.astype(np.float) / (x.sum()/3), axis = 1, raw = True)\n",
    "\n",
    "    movement_hist_test.iloc[:,3:-1] = movement_hist_test.iloc[:, 3:-1]\\\n",
    "            .apply(lambda x: x.astype(np.float) / (x.sum()/3), axis = 1, raw = True)\n",
    "    \n",
    "    mv_index = movement_hist_train['sup_art_movement'].value_counts().index[:num_movements]\n",
    "    train = movement_hist_train[movement_hist_train['sup_art_movement'].isin(mv_index)]\n",
    "    test = movement_hist_test[movement_hist_test['sup_art_movement'].isin(mv_index)]\n",
    "    \n",
    "    train_label = train['sup_art_movement']\n",
    "    test_label = test['sup_art_movement']\n",
    "    \n",
    "    print 'top movement for train:\\n %s ' % str(train['sup_art_movement'].value_counts())\n",
    "    print '-' * 50\n",
    "    print 'top movement for test:\\n %s ' % str(test['sup_art_movement'].value_counts())\n",
    "\n",
    "    test = test.drop(['author_id', 'painting_id', 'sup_art_movement'], axis=1)\n",
    "    train = train.drop(['author_id', 'painting_id', 'sup_art_movement'], axis=1)\n",
    "    \n",
    "    return train, train_label, test, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def movement_encod(train_labels, test_labels):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_labels)\n",
    "    le.classes_\n",
    "    train_labels_encd = le.transform(train_labels)\n",
    "    test_labels_encd = le.transform(test_labels)\n",
    "    \n",
    "    print \"[INFO] the original train labels: %s\" % str(train_labels.unique())\n",
    "    print \"[INFO] the encoded labels: %s\" % str(train_labels_encd)\n",
    "    \n",
    "    print '-' * 50\n",
    "    print \"[INFO] the original train labels: %s\" % str(test_labels.unique())\n",
    "    print \"[INFO] the encoded labels: %s\" % str(test_labels_encd)\n",
    "    \n",
    "    return train_labels_encd, test_labels_encd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The size of train histogram for Random Forest(67059, 34)\n",
      "[INFO] The size of test histogram for Random Forest(28740, 34)\n",
      "top movement for train:\n",
      " Impressionist    12694\n",
      "Baroque           9119\n",
      "Realist           8020\n",
      "Name: sup_art_movement, dtype: int64 \n",
      "--------------------------------------------------\n",
      "top movement for test:\n",
      " Impressionist    5441\n",
      "Baroque          3909\n",
      "Realist          3438\n",
      "Name: sup_art_movement, dtype: int64 \n"
     ]
    }
   ],
   "source": [
    "train, train_labels_y, test, test_labels_y = get_top_movement(3)\n",
    "train_labels, test_labels = movement_encod(train_labels_y, test_labels_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'random_forest_mv.sav'\n",
    "pickle.dump(best_mv_rfc, open(filename, 'wb'))\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_rfc_mv = pickle.load(open(filename, 'rb'))\n",
    "result_mv = loaded_rfc_mv.score(mv_transformed_test, test_labels)\n",
    "print(result_mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] the original train labels: ['Impressionist' 'Realist' 'Baroque']\n",
      "[INFO] the encoded labels: [1 2 1 ..., 1 1 1]\n",
      "--------------------------------------------------\n",
      "[INFO] the original train labels: ['Impressionist' 'Baroque' 'Realist']\n",
      "[INFO] the encoded labels: [1 0 2 ..., 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# encoding the labels\n",
    "train_labels, test_labels = movement_encod(train_labels_y, test_labels_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hist_01</th>\n",
       "      <th>hist_02</th>\n",
       "      <th>hist_03</th>\n",
       "      <th>hist_04</th>\n",
       "      <th>hist_05</th>\n",
       "      <th>hist_06</th>\n",
       "      <th>hist_07</th>\n",
       "      <th>hist_08</th>\n",
       "      <th>hist_09</th>\n",
       "      <th>hist_10</th>\n",
       "      <th>...</th>\n",
       "      <th>hist_22</th>\n",
       "      <th>hist_23</th>\n",
       "      <th>hist_24</th>\n",
       "      <th>hist_25</th>\n",
       "      <th>hist_26</th>\n",
       "      <th>hist_27</th>\n",
       "      <th>hist_28</th>\n",
       "      <th>hist_29</th>\n",
       "      <th>hist_30</th>\n",
       "      <th>height_width_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094590</td>\n",
       "      <td>0.00412</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.011424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106099</td>\n",
       "      <td>0.156601</td>\n",
       "      <td>0.160713</td>\n",
       "      <td>0.113880</td>\n",
       "      <td>0.111338</td>\n",
       "      <td>0.217190</td>\n",
       "      <td>0.169643</td>\n",
       "      <td>0.482321</td>\n",
       "      <td>0.019508</td>\n",
       "      <td>0.690840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063094</td>\n",
       "      <td>0.00524</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381769</td>\n",
       "      <td>0.227998</td>\n",
       "      <td>0.073087</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>0.186032</td>\n",
       "      <td>0.292737</td>\n",
       "      <td>0.239194</td>\n",
       "      <td>0.196291</td>\n",
       "      <td>0.085746</td>\n",
       "      <td>0.527901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.124335</td>\n",
       "      <td>0.00810</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465251</td>\n",
       "      <td>0.348895</td>\n",
       "      <td>0.076763</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>0.360181</td>\n",
       "      <td>0.454496</td>\n",
       "      <td>0.139565</td>\n",
       "      <td>0.018342</td>\n",
       "      <td>0.027415</td>\n",
       "      <td>0.811111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hist_01  hist_02   hist_03   hist_04   hist_05   hist_06   hist_07  \\\n",
       "0  0.094590  0.00412  0.000419  0.000082  0.000274  0.000865  0.000382   \n",
       "2  0.063094  0.00524  0.001453  0.000759  0.001086  0.001455  0.000944   \n",
       "4  0.124335  0.00810  0.001026  0.000261  0.000351  0.000437  0.000239   \n",
       "\n",
       "    hist_08   hist_09   hist_10         ...           hist_22   hist_23  \\\n",
       "0  0.001025  0.001423  0.011424         ...          0.106099  0.156601   \n",
       "2  0.001589  0.001935  0.002789         ...          0.381769  0.227998   \n",
       "4  0.000575  0.000998  0.002243         ...          0.465251  0.348895   \n",
       "\n",
       "    hist_24   hist_25   hist_26   hist_27   hist_28   hist_29   hist_30  \\\n",
       "0  0.160713  0.113880  0.111338  0.217190  0.169643  0.482321  0.019508   \n",
       "2  0.073087  0.014147  0.186032  0.292737  0.239194  0.196291  0.085746   \n",
       "4  0.076763  0.003930  0.360181  0.454496  0.139565  0.018342  0.027415   \n",
       "\n",
       "   height_width_ratio  \n",
       "0            0.690840  \n",
       "2            0.527901  \n",
       "4            0.811111  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.090507  ,  0.78338848,  1.23994181])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = np.bincount(train_labels)\n",
    "avg_count = counts.mean()\n",
    "class_weights = avg_count / counts\n",
    "# class_weights = dict([(key, total_samples / (num_classes\n",
    "#                                              * np.bincount(key)))])\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rf_evaluate(max_features, max_depth, n_estimators):\n",
    "    \n",
    "    random.seed(2017)\n",
    "#     params['max_features'] = int(max_features)\n",
    "#     params['max_depth'] = int(max_depth)\n",
    "#     params['n_estimators'] = int(n_estimators)\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_jobs = 4, n_estimators=int(n_estimators), oob_score=True,\n",
    "                                max_depth = int(max_depth), max_features = int(max_features), \n",
    "                                 class_weight='balanced')\n",
    "    #scores = cross_val_score(rfc, X=train, y = train_labels, cv=5, n_jobs = 2)\n",
    "    \n",
    "    # The mean score and the 95% confidence interval of the score estimate are hence given by:\n",
    "    #print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    #return scores.mean()\n",
    "    rfc.fit(train, train_labels)\n",
    "    return rfc.oob_score_\n",
    "\n",
    "def rf_pca_evaluate(max_features,\n",
    "                    max_depth,\n",
    "                    n_estimators):\n",
    "    \n",
    "    random.seed(2017)\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_jobs = 4, n_estimators=int(n_estimators), oob_score=True,\n",
    "                                max_depth = int(max_depth), max_features = int(max_features), \n",
    "                                 class_weight='balanced')\n",
    "    \n",
    "    rfc.fit(pca_transformed, train_labels)\n",
    "    return rfc.oob_score_\n",
    "\n",
    "def rf_bo(rf_fnc=rf_evaluate):\n",
    "    start_time = time.time()\n",
    "    num_iter = 25\n",
    "    init_points = 5\n",
    "    random_state = 2017\n",
    "    # params = {\n",
    "    #     #'eta': 0.1,\n",
    "    #     #'silent': 1,\n",
    "    #     'eval_metric': 'mae',\n",
    "    #     'verbose_eval': True,\n",
    "    #     #'seed': random_state\n",
    "    # }\n",
    "\n",
    "    rfBO = BayesianOptimization(rf_fnc, {'max_features': (5, 7),\n",
    "                                             'max_depth': (2, 10),\n",
    "                                             'n_estimators': (100, 720)})\n",
    "\n",
    "    rfBO.maximize(init_points=init_points, n_iter=num_iter)\n",
    "    print('-' * 53)\n",
    "    print 'Costed time: \\n%f' % (time.time() - start_time)\n",
    "    \n",
    "    print \"Bayesian Optimization Best Score: %f\" % rfBO.res['max']['max_val']\n",
    "\n",
    "    print \"Bayesian Optimization Best Parameters: %s\" % str(rfBO.res['max']['max_params'])\n",
    "    \n",
    "    print (rfBO.res['max'])\n",
    "    \n",
    "#     fns.plot_bo(rf_fnc, rfBO)\n",
    "\n",
    "#     print \"Bayesian Optimization  Parameters: %s\" % str(rfBO.res['all'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   max_features |   n_estimators | \n",
      "    1 | 00m03s | \u001b[35m   0.62367\u001b[0m | \u001b[32m     5.8683\u001b[0m | \u001b[32m        6.0361\u001b[0m | \u001b[32m      112.0690\u001b[0m | \n",
      "    2 | 00m07s | \u001b[35m   0.63014\u001b[0m | \u001b[32m     6.6130\u001b[0m | \u001b[32m        6.4626\u001b[0m | \u001b[32m      186.6227\u001b[0m | \n",
      "    3 | 00m13s |    0.62987 |      6.7922 |         6.7888 |       332.3277 | \n",
      "    4 | 00m17s | \u001b[35m   0.64345\u001b[0m | \u001b[32m     8.2729\u001b[0m | \u001b[32m        5.0850\u001b[0m | \u001b[32m      408.0840\u001b[0m | \n",
      "    5 | 00m09s |    0.63708 |      7.7347 |         5.6095 |       255.3776 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   max_features |   n_estimators | \n",
      "    6 | 00m45s | \u001b[35m   0.65039\u001b[0m | \u001b[32m     9.1150\u001b[0m | \u001b[32m        5.8077\u001b[0m | \u001b[32m      719.9511\u001b[0m | \n",
      "    7 | 00m13s |    0.59629 |      2.0000 |         5.0619 |       582.2376 | \n",
      "    8 | 00m17s |    0.60074 |      2.0845 |         5.7389 |       719.9915 | \n",
      "    9 | 00m36s | \u001b[35m   0.65542\u001b[0m | \u001b[32m    10.0000\u001b[0m | \u001b[32m        7.0000\u001b[0m | \u001b[32m      495.3132\u001b[0m | \n",
      "   10 | 00m39s |    0.64982 |      9.9865 |         6.8118 |       658.3467 | \n",
      "   11 | 00m25s |    0.64878 |      9.9425 |         5.0439 |       455.4347 | \n",
      "   12 | 00m29s |    0.65082 |      9.9734 |         5.2877 |       536.9350 | \n",
      "   13 | 00m36s |    0.65042 |      9.9763 |         5.8085 |       691.6349 | \n",
      "   14 | 00m24s |    0.65062 |      9.9978 |         6.8561 |       375.9225 | \n",
      "   15 | 00m33s |    0.64992 |      9.9838 |         5.1154 |       620.1688 | \n",
      "   16 | 00m21s |    0.64797 |      9.9683 |         6.7488 |       292.4229 | \n",
      "   17 | 00m13s |    0.64734 |      9.9637 |         5.2713 |       148.9383 | \n",
      "   18 | 00m32s |    0.65032 |      9.9465 |         5.0048 |       514.7536 | \n",
      "   19 | 00m31s |    0.64958 |     10.0000 |         7.0000 |       428.8287 | \n",
      "   20 | 00m20s |    0.65032 |      9.9883 |         6.4749 |       225.4196 | \n",
      "   21 | 00m40s |    0.64911 |     10.0000 |         7.0000 |       567.3020 | \n",
      "   22 | 00m35s |    0.64881 |      9.9985 |         6.9083 |       475.4231 | \n",
      "   23 | 00m47s |    0.64982 |      9.9588 |         6.9922 |       710.5096 | \n",
      "   24 | 00m33s |    0.64975 |      9.9603 |         5.1383 |       492.9200 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -7.20817334e-05]), 'nit': 7, 'funcalls': 58}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 | 00m41s |    0.64952 |      9.9532 |         6.9824 |       595.8026 | \n",
      "   26 | 00m31s |    0.64962 |      9.9877 |         6.9083 |       397.3274 | \n",
      "   27 | 00m44s |    0.64931 |      9.9773 |         6.8364 |       641.1409 | \n",
      "   28 | 00m30s |    0.64838 |      9.9671 |         6.9986 |       357.9955 | \n",
      "   29 | 00m37s |    0.64955 |      9.9690 |         6.9393 |       506.4281 | \n",
      "   30 | 00m15s |    0.64559 |      9.8229 |         6.9007 |       100.0475 | \n",
      "-----------------------------------------------------\n",
      "Costed time: \n",
      "830.827121\n",
      "Bayesian Optimization Best Score: 0.655415\n",
      "Bayesian Optimization Best Parameters: {'max_features': 7.0, 'n_estimators': 495.31321322424282, 'max_depth': 10.0}\n",
      "{'max_val': 0.65541514430328829, 'max_params': {'max_features': 7.0, 'n_estimators': 495.31321322424282, 'max_depth': 10.0}}\n"
     ]
    }
   ],
   "source": [
    "# Run BO for color histogram\n",
    "rf_bo(rf_evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Model on training set:0.769885697047\n",
      "Accuracy of the Model on testing set:0.653737879262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 2, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the best params from BO results then predict \n",
    "best_mv_estimators = 495\n",
    "best_mv_max_depth = 10\n",
    "best_mv_max_features = 7\n",
    "best_mv_rfc = RandomForestClassifier(n_jobs = 4, n_estimators=best_mv_estimators, oob_score=False,\n",
    "                                max_depth = best_mv_max_depth, max_features = best_mv_max_features)\n",
    "\n",
    "best_mv_rfc.fit(train, train_labels)\n",
    "\n",
    "# accuracy for the train set\n",
    "print \"Accuracy of the Model on training set:\" + str(best_mv_rfc.score(train,train_labels))\n",
    "\n",
    "# accuracy for the test set\n",
    "print \"Accuracy of the Model on testing set:\" + str(best_mv_rfc.score(test,test_labels))\n",
    "\n",
    "# use the best params to predict\n",
    "rfc_mv_true, rfc_mv_pred = test_labels, best_mv_rfc.predict(test)\n",
    "rfc_mv_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.653737879262\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'random_forest_mv.sav'\n",
    "pickle.dump(best_mv_rfc, open(filename, 'wb'))\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_rfc_mv = pickle.load(open(filename, 'rb'))\n",
    "result_mv = loaded_rfc_mv.score(test, test_labels)\n",
    "print(result_mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "movement_hist_train = pd.read_csv('data/movement_hist_train.csv')\n",
    "top_movements = dict(movement_hist_train['sup_art_movement'].value_counts()[:3])\n",
    "\n",
    "total_samples = sum(top_movements.values())\n",
    "class_weights = dict([(key, total_samples / (float(len(top_movements))\n",
    "                                             * top_movements[key]))\n",
    "                      for key in top_movements])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Baroque': 1.0905070000365538,\n",
       " 'Impressionist': 0.78338847749592988,\n",
       " 'Realist': 1.2399418121363259}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>painting_id</th>\n",
       "      <th>sup_art_movement</th>\n",
       "      <th>hist_01</th>\n",
       "      <th>hist_02</th>\n",
       "      <th>hist_03</th>\n",
       "      <th>hist_04</th>\n",
       "      <th>hist_05</th>\n",
       "      <th>hist_06</th>\n",
       "      <th>hist_07</th>\n",
       "      <th>...</th>\n",
       "      <th>hist_22</th>\n",
       "      <th>hist_23</th>\n",
       "      <th>hist_24</th>\n",
       "      <th>hist_25</th>\n",
       "      <th>hist_26</th>\n",
       "      <th>hist_27</th>\n",
       "      <th>hist_28</th>\n",
       "      <th>hist_29</th>\n",
       "      <th>hist_30</th>\n",
       "      <th>height_width_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>2976</td>\n",
       "      <td>Impressionist</td>\n",
       "      <td>0.094590</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106099</td>\n",
       "      <td>0.156601</td>\n",
       "      <td>0.160713</td>\n",
       "      <td>0.113880</td>\n",
       "      <td>0.111338</td>\n",
       "      <td>0.217190</td>\n",
       "      <td>0.169643</td>\n",
       "      <td>0.482321</td>\n",
       "      <td>0.019508</td>\n",
       "      <td>0.690840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91</td>\n",
       "      <td>494</td>\n",
       "      <td>Realist</td>\n",
       "      <td>0.063094</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381769</td>\n",
       "      <td>0.227998</td>\n",
       "      <td>0.073087</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>0.186032</td>\n",
       "      <td>0.292737</td>\n",
       "      <td>0.239194</td>\n",
       "      <td>0.196291</td>\n",
       "      <td>0.085746</td>\n",
       "      <td>0.527901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>368</td>\n",
       "      <td>53036</td>\n",
       "      <td>Impressionist</td>\n",
       "      <td>0.124335</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465251</td>\n",
       "      <td>0.348895</td>\n",
       "      <td>0.076763</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>0.360181</td>\n",
       "      <td>0.454496</td>\n",
       "      <td>0.139565</td>\n",
       "      <td>0.018342</td>\n",
       "      <td>0.027415</td>\n",
       "      <td>0.811111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>106</td>\n",
       "      <td>14548</td>\n",
       "      <td>Impressionist</td>\n",
       "      <td>0.098685</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>0.005334</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.004421</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271754</td>\n",
       "      <td>0.039882</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>0.006078</td>\n",
       "      <td>0.063172</td>\n",
       "      <td>0.069721</td>\n",
       "      <td>0.134975</td>\n",
       "      <td>0.344031</td>\n",
       "      <td>0.388102</td>\n",
       "      <td>0.854111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>425</td>\n",
       "      <td>13226</td>\n",
       "      <td>Realist</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117547</td>\n",
       "      <td>0.454616</td>\n",
       "      <td>0.326103</td>\n",
       "      <td>0.096591</td>\n",
       "      <td>0.305860</td>\n",
       "      <td>0.277820</td>\n",
       "      <td>0.140600</td>\n",
       "      <td>0.166135</td>\n",
       "      <td>0.109585</td>\n",
       "      <td>0.697830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    author_id  painting_id sup_art_movement   hist_01   hist_02   hist_03  \\\n",
       "0          13         2976    Impressionist  0.094590  0.004120  0.000419   \n",
       "2          91          494          Realist  0.063094  0.005240  0.001453   \n",
       "4         368        53036    Impressionist  0.124335  0.008100  0.001026   \n",
       "9         106        14548    Impressionist  0.098685  0.018106  0.005334   \n",
       "12        425        13226          Realist  0.000022  0.000006  0.000006   \n",
       "\n",
       "     hist_04   hist_05   hist_06   hist_07         ...           hist_22  \\\n",
       "0   0.000082  0.000274  0.000865  0.000382         ...          0.106099   \n",
       "2   0.000759  0.001086  0.001455  0.000944         ...          0.381769   \n",
       "4   0.000261  0.000351  0.000437  0.000239         ...          0.465251   \n",
       "9   0.002374  0.003337  0.004421  0.003590         ...          0.271754   \n",
       "12  0.000003  0.000003  0.000003  0.000016         ...          0.117547   \n",
       "\n",
       "     hist_23   hist_24   hist_25   hist_26   hist_27   hist_28   hist_29  \\\n",
       "0   0.156601  0.160713  0.113880  0.111338  0.217190  0.169643  0.482321   \n",
       "2   0.227998  0.073087  0.014147  0.186032  0.292737  0.239194  0.196291   \n",
       "4   0.348895  0.076763  0.003930  0.360181  0.454496  0.139565  0.018342   \n",
       "9   0.039882  0.009033  0.006078  0.063172  0.069721  0.134975  0.344031   \n",
       "12  0.454616  0.326103  0.096591  0.305860  0.277820  0.140600  0.166135   \n",
       "\n",
       "     hist_30  height_width_ratio  \n",
       "0   0.019508            0.690840  \n",
       "2   0.085746            0.527901  \n",
       "4   0.027415            0.811111  \n",
       "9   0.388102            0.854111  \n",
       "12  0.109585            0.697830  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features=2, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=2, n_jobs=4, oob_score=True, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "le.classes_\n",
    "train_labels_encd = le.transform(train_labels)\n",
    "test_labels_encd = le.transform(test_labels)\n",
    "test_labels_encd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>color_hist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.653738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.676024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name  color_hist\n",
       "0  random_forest    0.653738\n",
       "1            xgb    0.676024"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict art movement\n",
    "random_forest = ['random_forest', 0.653737879262]\n",
    "xgboost = ['xgb', 0.676024397873]\n",
    "pd.DataFrame([random_forest, xgboost], columns=['model_name', 'color_hist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>color_hist</th>\n",
       "      <th>pca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.599407</td>\n",
       "      <td>0.623145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>extra_tree</td>\n",
       "      <td>0.673591</td>\n",
       "      <td>0.660732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.686449</td>\n",
       "      <td>0.668645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grad_boost</td>\n",
       "      <td>0.747774</td>\n",
       "      <td>0.729970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.794409</td>\n",
       "      <td>0.713155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name  color_hist       pca\n",
       "0    naive_bayes    0.599407  0.623145\n",
       "1     extra_tree    0.673591  0.660732\n",
       "2  random_forest    0.686449  0.668645\n",
       "3     grad_boost    0.747774  0.729970\n",
       "4        xgboost    0.794409  0.713155"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict authors\n",
    "random_forest = ['random_forest', 0.686449060336, 0.668644906034]\n",
    "xgboost = ['xgboost', 0.79440870856, 0.71315529179]\n",
    "naive_bayes = ['naive_bayes', 0.59940652819, 0.623145400593]\n",
    "extra_tree = ['extra_tree', 0.673590504451, 0.660731948566]\n",
    "grad_boost = ['grad_boost', 0.747774480712, 0.729970326409]\n",
    "pd.DataFrame([naive_bayes, extra_tree, random_forest, grad_boost, xgboost], columns=['model_name', 'color_hist', 'pca'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
