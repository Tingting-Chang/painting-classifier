{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named xgboost",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b6fe7539aea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbayes_opt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named xgboost"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import fns_models as fns\n",
    "\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output(['ls', 'data']).decode('utf-8'))\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The size of train histogram for Random Forest(49890, 34)\n",
      "[INFO] The size of test histogram for Random Forest(12473, 34)\n"
     ]
    }
   ],
   "source": [
    "# Pick top 3 authors\n",
    "def get_top_author(num_author=3):\n",
    "    train = pd.read_csv(\"data/train_hist_author_knn.csv\")\n",
    "    test = pd.read_csv(\"data/test_hist_author_knn.csv\")\n",
    "\n",
    "    print \"[INFO] The size of train histogram for Random Forest\" + str(train.shape)\n",
    "    print \"[INFO] The size of test histogram for Random Forest\" + str(test.shape)\n",
    "\n",
    "     \n",
    "    train.iloc[:,2:-2] = train.iloc[:, 2:-2]\\\n",
    "        .apply(lambda x: x.astype(np.float) / (x.sum()/3), axis = 1, raw = True)\n",
    "    test.iloc[:,2:-2] = test.iloc[:, 2:-2]\\\n",
    "        .apply(lambda x: x.astype(np.float) / (x.sum()/3), axis = 1, raw = True)\n",
    "        \n",
    "    author_index = train.author_id.value_counts().index[:num_author]\n",
    "    train = train.loc[train['author_id'].isin(author_index)]\n",
    "    test = test.loc[test['author_id'].isin(author_index)]\n",
    "    \n",
    "    \n",
    "    print train.author_id.value_counts().head(10)\n",
    "    print \"[trian above] \" + '=' * 50 + \"[test below]\"\n",
    "    print test.author_id.value_counts().head(10)\n",
    "    \n",
    "\n",
    "    train_labels = train.author_id\n",
    "    print train_labels.shape\n",
    "    print  train.shape\n",
    "    train = train.drop(['author_id', 'painting_id'], axis=1)\n",
    "    test_labels = test.author_id\n",
    "    test = test.drop(['author_id', 'painting_id'], axis=1)\n",
    "   \n",
    "    return train, train_labels, test, test_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, train_labels, test, test_labels = fns.get_top_author(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================================================================\n",
    "\n",
    "# Bayesian Optimization\n",
    "\n",
    "[bayesian-optimization](https://scikit-optimize.github.io/notebooks/bayesian-optimization.html)\n",
    "\n",
    "================================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_evaluate(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma,\n",
    "                 alpha):\n",
    "\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['cosample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    params['alpha'] = max(alpha, 0)\n",
    "\n",
    "\n",
    "    cv_result = xgb.cv(params, xgtrain, num_boost_round=num_rounds, nfold=5,\n",
    "             seed=random_state,\n",
    "             callbacks=[xgb.callback.early_stop(50)])\n",
    "\n",
    "    return -cv_result['test-mae-mean'].values[-1]\n",
    "\n",
    "\n",
    "def xgb_pca_evaluate(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma,\n",
    "                 alpha):\n",
    "\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['cosample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    params['alpha'] = max(alpha, 0)\n",
    "\n",
    "\n",
    "    cv_result = xgb.cv(params, pca_transformed, num_boost_round=num_rounds, nfold=5,\n",
    "             seed=random_state,\n",
    "             callbacks=[xgb.callback.early_stop(50)])\n",
    "\n",
    "    return -cv_result['test-mae-mean'].values[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain, xgtrain_labels, xgtest, xgtest_labels = fns.get_top_author(3)\n",
    "\n",
    "def xgb_bo(xgb_fn = xgb_evaluate):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    num_rounds = 3000\n",
    "    random_state = 2017\n",
    "    num_iter = 25\n",
    "    init_points = 5\n",
    "    params = {\n",
    "        'eta': 0.1,\n",
    "        'silent': 1,\n",
    "        'eval_metric': 'mae',\n",
    "        'verbose_eval': True,\n",
    "        'seed': random_state\n",
    "    }\n",
    "\n",
    "    xgbBO = BayesianOptimization(xgb_fn, {'min_child_weight': (1, 20),\n",
    "                                                'colsample_bytree': (0.1, 1),\n",
    "                                                'max_depth': (5, 15),\n",
    "                                                'subsample': (0.5, 1),\n",
    "                                                'gamma': (0, 10),\n",
    "                                                'alpha': (0, 10),\n",
    "                                                })\n",
    "\n",
    "    xgbBO.maximize(init_points=init_points, n_iter=num_iter)\n",
    "    print('-' * 53)\n",
    "    print '\\n%f' % (time.time() - start_time)\n",
    "\n",
    "    print('-' * 53)\n",
    "    print('Final Results')\n",
    "    print('XGboost: %f' % xgbBO.res['max']['max_val'])\n",
    "    print('-' * 53)\n",
    "    print('XGboost: %f' % xgbBO.res['max'])\n",
    "    fns.plot_bo(xgb_fn, xgbBO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run BO for color histogram\n",
    "xgb_bo(xgb_evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose the best params from BO results then predict \n",
    "best_min_child_weight = \n",
    "best_colsample_bytree = \n",
    "best_subsample = \n",
    "best_gamma = \n",
    "best_alpha = \n",
    "best_xgb = xgb(n_jobs = 4, min_child_weight=best_min_child_weight, colsample_bytree=best_colsample_bytree\n",
    "               max_depth = best_max_depth, subsample = best_subsample, gamma=gamma, alpha=best_alpha)\n",
    "\n",
    "best_xgb.fit(train, train_labels)\n",
    "\n",
    "# use the best params to predict\n",
    "xgb_true, xgb_pred = test_labels, best_xgb.predict(test)\n",
    "xgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_df = fns.result_table(xgb_true, xgb_pred)\n",
    "test_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PCA + XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PCA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-06deaf0e80c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Get 15 principal components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpca_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpca_transformed_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PCA' is not defined"
     ]
    }
   ],
   "source": [
    "## Get 15 principal components\n",
    "xgb_pca = PCA(n_components=15)\n",
    "xgb_pca.fit(train)\n",
    "xgb_pca_transformed = xgb_pca.transform(train)\n",
    "xgb_pca_transformed_test = xgb_pca.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.title(\"Scree Plot: 10 Principal Components\")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"% of Explained Variance\")\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run BO for pca of color histogram\n",
    "xgb_bo(xgb_pca_evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose the best params from BO results then predict \n",
    "best_min_child_weight = \n",
    "best_colsample_bytree = \n",
    "best_subsample = \n",
    "best_gamma = \n",
    "best_alpha = \n",
    "best_xgb = xgb(n_jobs = 4, min_child_weight=best_min_child_weight, colsample_bytree=best_colsample_bytree\n",
    "               max_depth = best_max_depth, subsample = best_subsample, gamma=gamma, alpha=best_alpha)\n",
    "\n",
    "best_xgb.fit(xgb_pca_transformed, train_labels)\n",
    "\n",
    "# use the best params to predict\n",
    "xgb_true, xgb_pred = test_labels, best_xgb.predict(xgb_pca_transformed_test)\n",
    "xgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_xgb.score(xgb_pca_transformed, train_labels)\n",
    "print \"Accuracy of best xgb model on training: %s\" % str(best_xgb.score)\n",
    "\n",
    "best_xgb.score(xgb_pca_transformed_test, test_labels)\n",
    "print \"Accuracy of best xgb model on testing: %s\" % str(best_xgb.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test_data_df = fns.result_table(xgb_true, xgb_pred)\n",
    "test_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
