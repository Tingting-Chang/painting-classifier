{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "============================================================================================\n",
    "\n",
    "# XGBoost\n",
    "\n",
    "\n",
    "============================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athenaeum_authors_preview.csv\n",
      "athenaeum_painting_filtered.csv\n",
      "athenaeum_paintings.csv\n",
      "athenaeum_paintings_sizes.csv\n",
      "color_histograms.csv\n",
      "complete_data.csv\n",
      "extra_tree_com.csv\n",
      "grad_boost_com.csv\n",
      "images\n",
      "images_athenaeum\n",
      "images_sizes_2325.csv\n",
      "net_predicted.csv\n",
      "painter_info_clean.csv\n",
      "painting_info_clean.csv\n",
      "resized_200\n",
      "rf_com.csv\n",
      "test_author200.csv\n",
      "test_data.csv\n",
      "test_hist_author_knn.csv\n",
      "test_hist_author_rf.csv\n",
      "train_author200.csv\n",
      "train_data.csv\n",
      "train_hist_author_knn.csv\n",
      "train_hist_author_rf.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import fns_models as fns\n",
    "\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output(['ls', 'data']).decode('utf-8'))\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The size of train histogram for Random Forest(49890, 35)\n",
      "[INFO] The size of test histogram for Random Forest(12473, 35)\n",
      "24      1369\n",
      "1793    1338\n",
      "368     1335\n",
      "Name: author_id, dtype: int64\n",
      "[trian above] ==================================================[test below]\n",
      "24      342\n",
      "1793    335\n",
      "368     334\n",
      "Name: author_id, dtype: int64\n",
      "(4042,)\n",
      "(4042, 35)\n"
     ]
    }
   ],
   "source": [
    "train, train_labels, test, test_labels = fns.get_top_author(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# train = train.sample(20)\n",
    "# train_labels = train_labels.sample(20)\n",
    "# test = test.sample(15)\n",
    "# test_labels = test_labels.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "================================================================================================================\n",
    "\n",
    "# Bayesian Optimization\n",
    "\n",
    "[bayesian-optimization](https://scikit-optimize.github.io/notebooks/bayesian-optimization.html)\n",
    "\n",
    "================================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[85]\ttrain-mae:151.908+2.87743\ttest-mae:438.859+7.19919\n",
      "\n",
      "    1 | 00m04s | \u001b[35m-438.85917\u001b[0m | \u001b[32m   1.4948\u001b[0m | \u001b[32m            0.4452\u001b[0m | \u001b[32m   8.6838\u001b[0m | \u001b[32m     8.7511\u001b[0m | \u001b[32m           13.5774\u001b[0m | \u001b[32m     0.8550\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[90]\ttrain-mae:51.563+1.75217\ttest-mae:441.627+11.5227\n",
      "\n",
      "    2 | 00m08s | -441.62706 |    6.1443 |             0.8798 |    3.3898 |     12.8317 |             9.4319 |      0.9236 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[58]\ttrain-mae:119.408+3.13666\ttest-mae:446.453+13.6401\n",
      "\n",
      "    3 | 00m05s | -446.45323 |    0.8591 |             0.6400 |    4.8179 |     11.8729 |             5.7442 |      0.5517 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[123]\ttrain-mae:182.339+2.28421\ttest-mae:443.027+14.0604\n",
      "\n",
      "    4 | 00m05s | -443.02710 |    1.9590 |             0.6445 |    4.4460 |      7.6533 |            15.0301 |      0.5846 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[80]\ttrain-mae:154.243+2.40641\ttest-mae:447.818+13.0815\n",
      "\n",
      "    5 | 00m05s | -447.81835 |    3.9949 |             0.7233 |    7.3840 |     11.4475 |            12.0158 |      0.5239 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[203]\ttrain-mae:170.016+3.51867\ttest-mae:441.612+10.103\n",
      "\n",
      "    6 | 00m11s | -441.61210 |   10.0000 |             0.1000 |   10.0000 |      5.0000 |             1.0000 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[97]\ttrain-mae:90.9114+2.69189\ttest-mae:440.087+9.81298\n",
      "\n",
      "    7 | 00m12s | -440.08748 |   10.0000 |             0.1000 |    0.0000 |     15.0000 |            20.0000 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[186]\ttrain-mae:220.257+3.98158\ttest-mae:443.194+8.65658\n",
      "\n",
      "    8 | 00m08s | -443.19373 |    0.0000 |             1.0000 |   10.0000 |      5.0000 |            20.0000 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mae:62.3811+0.539071\ttest-mae:445.63+13.8656\n",
      "\n",
      "    9 | 00m12s | -445.62964 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[63]\ttrain-mae:5.50483+0.509914\ttest-mae:460.911+14.098\n",
      "\n",
      "   10 | 00m14s | -460.91058 |   10.0000 |             1.0000 |    0.0000 |     15.0000 |             1.0000 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[128]\ttrain-mae:65.4177+5.36957\ttest-mae:438.675+8.73795\n",
      "\n",
      "   11 | 00m15s | \u001b[35m-438.67540\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m            0.1000\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m    15.0000\u001b[0m | \u001b[32m           20.0000\u001b[0m | \u001b[32m     1.0000\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[190]\ttrain-mae:180.805+6.38886\ttest-mae:442.174+10.8243\n",
      "\n",
      "   12 | 00m10s | -442.17445 |    0.0000 |             0.1000 |   10.0000 |      5.0000 |             1.0000 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[213]\ttrain-mae:181.226+5.81458\ttest-mae:443.746+10.2206\n",
      "\n",
      "   13 | 00m10s | -443.74625 |    0.0000 |             0.1000 |    0.0000 |      5.0000 |            10.8417 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[168]\ttrain-mae:214.812+4.26541\ttest-mae:443.33+12.9594\n",
      "\n",
      "   14 | 00m08s | -443.33028 |    0.0000 |             0.1000 |   10.0000 |      5.0000 |            12.4172 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[128]\ttrain-mae:65.4177+5.36957\ttest-mae:438.675+8.73795\n",
      "\n",
      "   15 | 00m15s | -438.67540 |    0.0000 |             1.0000 |   10.0000 |     15.0000 |            20.0000 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mae:62.3811+0.539071\ttest-mae:445.63+13.8656\n",
      "\n",
      "   16 | 00m13s | -445.62964 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mae:62.3811+0.539071\ttest-mae:445.63+13.8656\n",
      "\n",
      "   17 | 00m13s | -445.62964 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mae:62.3811+0.539071\ttest-mae:445.63+13.8656\n",
      "\n",
      "   18 | 00m13s | -445.62964 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mae:62.3811+0.539071\ttest-mae:445.63+13.8656\n",
      "\n",
      "   19 | 00m13s | -445.62964 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mae:62.3811+0.539071\ttest-mae:445.63+13.8656\n",
      "\n",
      "   20 | 00m13s | -445.62964 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mae:62.3811+0.539071\ttest-mae:445.63+13.8656\n",
      "\n",
      "   21 | 00m14s | -445.62964 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mae:62.3811+0.539071\ttest-mae:445.63+13.8656\n",
      "\n",
      "   22 | 00m13s | -445.62964 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mae:62.3811+0.539071\ttest-mae:445.63+13.8656\n",
      "\n",
      "   23 | 00m15s | -445.62964 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mae:62.3811+0.539071\ttest-mae:445.63+13.8656\n",
      "\n",
      "   24 | 00m14s | -445.62964 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mae:62.3811+0.539071\ttest-mae:445.63+13.8656\n",
      "\n",
      "   25 | 00m14s | -445.62964 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mae:62.3811+0.539071\ttest-mae:445.63+13.8656\n",
      "\n",
      "   26 | 00m13s | -445.62964 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mae:62.3811+0.539071\ttest-mae:445.63+13.8656\n",
      "\n",
      "   27 | 00m14s | -445.62964 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mae:62.3811+0.539071\ttest-mae:445.63+13.8656\n",
      "\n",
      "   28 | 00m13s | -445.62964 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mae:62.3811+0.539071\ttest-mae:445.63+13.8656\n",
      "\n",
      "   29 | 00m13s | -445.62964 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-mae:62.3811+0.539071\ttest-mae:445.63+13.8656\n",
      "\n",
      "   30 | 00m14s | -445.62964 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Baysian hyperparameter optimization [https://github.com/fmfn/BayesianOptimization]\n",
    "for Mean Absoulte Error objective\n",
    "on default features for https://www.kaggle.com/c/allstate-claims-severity\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def xgb_evaluate(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma,\n",
    "                 alpha):\n",
    "\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['cosample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    params['alpha'] = max(alpha, 0)\n",
    "\n",
    "\n",
    "    cv_result = xgb.cv(params, xgtrain, num_boost_round=num_rounds, nfold=5,\n",
    "             seed=random_state,\n",
    "             callbacks=[xgb.callback.early_stop(50)])\n",
    "\n",
    "    return -cv_result['test-mae-mean'].values[-1]\n",
    "\n",
    "\n",
    "def prepare_data(train, train_labels):\n",
    "    train = train\n",
    "    categorical_columns = train.select_dtypes(include=['object']).columns\n",
    "\n",
    "    for column in tqdm(categorical_columns):\n",
    "        le = LabelEncoder()\n",
    "        train[column] = le.fit_transform(train[column])\n",
    "\n",
    "    y = train_labels\n",
    "\n",
    "    X = train\n",
    "    xgtrain = xgb.DMatrix(X, label=y)\n",
    "\n",
    "    return xgtrain\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    xgtrain = prepare_data(train, train_labels)\n",
    "    \n",
    "    num_rounds = 3000\n",
    "    random_state = 2016\n",
    "    num_iter = 25\n",
    "    init_points = 5\n",
    "    params = {\n",
    "        'eta': 0.1,\n",
    "        'silent': 1,\n",
    "        'eval_metric': 'mae',\n",
    "        'verbose_eval': True,\n",
    "        'seed': random_state\n",
    "    }\n",
    "\n",
    "    xgbBO = BayesianOptimization(xgb_evaluate, {'min_child_weight': (1, 20),\n",
    "                                                'colsample_bytree': (0.1, 1),\n",
    "                                                'max_depth': (5, 15),\n",
    "                                                'subsample': (0.5, 1),\n",
    "                                                'gamma': (0, 10),\n",
    "                                                'alpha': (0, 10),\n",
    "                                                })\n",
    "\n",
    "    xgbBO.maximize(init_points=init_points, n_iter=num_iter)\n",
    "    \n",
    "    print \"Best Params %s\" % str(xgbBO.res['max'])\n",
    "    \n",
    "    # xgtrain.get_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X',\n",
       " 'Y',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'bounds',\n",
       " 'dim',\n",
       " 'explore',\n",
       " 'f',\n",
       " 'gp',\n",
       " 'i',\n",
       " 'init',\n",
       " 'init_points',\n",
       " 'initialize',\n",
       " 'initialize_df',\n",
       " 'initialized',\n",
       " 'keys',\n",
       " 'maximize',\n",
       " 'pbounds',\n",
       " 'plog',\n",
       " 'points_to_csv',\n",
       " 'res',\n",
       " 'set_bounds',\n",
       " 'util',\n",
       " 'verbose',\n",
       " 'x_init',\n",
       " 'y_init']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(xgbBO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def prepare_model_data(train, train_labels, test, test_labels):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_labels)\n",
    "    le.classes_\n",
    "    train_labels_encd = le.transform(train_labels)\n",
    "    test_labels_encd = le.transform(test_labels)\n",
    "    \n",
    "    xgtrain = xgb.DMatrix(train, label=train_labels_encd)\n",
    "    xgtest = xgb.DMatrix(test, label=test_labels_encd)\n",
    "    \n",
    "    return train_labels_encd, test_labels_encd, xgtrain, xgtest\n",
    "\n",
    "# train_labels_encd, test_labels_encd, xgtrain, xgtest = prepare_model_data(train, train_labels, test, test_labels)\n",
    "\n",
    "def get_xgb_score(y_true, y_pred):\n",
    "    if type(y_true[0] != y_pred[0]):\n",
    "        y_true = np.array(y_true, dtype=np.int64)\n",
    "        y_pred = np.array(y_pred, dtype=np.int64)\n",
    "    return (y_true == y_pred).mean()\n",
    "\n",
    "\n",
    "def get_transformed_class(y_pred):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_labels)\n",
    "    le.classes_\n",
    "    return [le.inverse_transform(int(x)) for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_labels_encd, test_labels_encd, xgtrain, xgtest = prepare_model_data(train, train_labels, test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Model on training set:0.975012370114\n",
      "Accuracy of the Model on testing set:0.77546983185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  2., ...,  2.,  0.,  2.], dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the best params from BO results then predict \n",
    "best_min_child_weight = 18\n",
    "best_colsample_bytree = 0.6\n",
    "best_subsample = 0.75\n",
    "best_gamma = 2\n",
    "best_alpha = 0.14\n",
    "best_max_depth = 10\n",
    "\n",
    "num_round = 1000\n",
    "\n",
    "params['objective'] = 'multi:softmax'\n",
    "params['num_class'] = 3\n",
    "params['eval_metric'] = \"mlogloss\"\n",
    "params['min_child_weight'] = best_min_child_weight\n",
    "params['colsample_bytree'] = best_colsample_bytree\n",
    "params['max_depth'] = best_max_depth\n",
    "params['subsample'] = best_subsample\n",
    "params['gamma'] = best_gamma\n",
    "params['alpha'] = best_alpha\n",
    "\n",
    "best_xgb = xgb.train(params, xgtrain, num_round)\n",
    "best_xgb.save_model('models/xgb')\n",
    "\n",
    "\n",
    "best_xgb_pred = best_xgb.predict(xgtrain)\n",
    "\n",
    "# accuracy for the train set\n",
    "print \"Accuracy of the Model on training set:\" + str(get_xgb_score(train_labels_encd, best_xgb_pred))\n",
    "\n",
    "# accuracy for the test set\n",
    "print \"Accuracy of the Model on testing set:\" + str(get_xgb_score(test_labels_encd, best_xgb_pred_test))\n",
    "\n",
    "\n",
    "# use the best params to predict\n",
    "xgb_true, xgb_pred = test_labels, best_xgb.predict(xgtest)\n",
    "xgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 368,\n",
       " 1793,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 1793,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 1793,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 1793,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 368,\n",
       " 24,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 368,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 368,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 368,\n",
       " 1793,\n",
       " 368,\n",
       " 368,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " 24,\n",
       " 1793,\n",
       " 24,\n",
       " ...]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_true, xgb_pred = test_labels, best_xgb.predict(xgtest)\n",
    "xgb_pred = get_transformed_class(xgb_pred)\n",
    "xgb_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{24, 368, 1793}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_transformed_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_xgb_pred_test = best_xgb.predict(xgtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77546983184965379"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(best_xgb_pred_test == test_labels_encd).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  2.,  2., ...,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xgb_pred = [le.inverse_transform(int(x)) for x in xgb_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1793"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "?xgb.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>xgb_pred</th>\n",
       "      <th>xgb_res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>24</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>24</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9715</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9716</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9718</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9720</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9726</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9727</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9729</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9730</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9731</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9732</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9734</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9735</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9746</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9749</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9752</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9753</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9756</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9757</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9758</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9759</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1011 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual  xgb_pred xgb_res\n",
       "33        24        24    True\n",
       "34      1793      1793    True\n",
       "35      1793      1793    True\n",
       "37      1793      1793    True\n",
       "101     1793      1793    True\n",
       "102     1793      1793    True\n",
       "105     1793      1793    True\n",
       "217     1793      1793    True\n",
       "261     1793      1793    True\n",
       "295     1793      1793    True\n",
       "354     1793      1793    True\n",
       "355     1793        24   False\n",
       "399     1793      1793    True\n",
       "474     1793      1793    True\n",
       "507     1793      1793    True\n",
       "545     1793      1793    True\n",
       "554       24        24    True\n",
       "604       24        24    True\n",
       "607       24        24    True\n",
       "608       24        24    True\n",
       "662       24        24    True\n",
       "686     1793      1793    True\n",
       "710     1793      1793    True\n",
       "860       24        24    True\n",
       "861       24       368   False\n",
       "862       24      1793   False\n",
       "863       24        24    True\n",
       "864       24       368   False\n",
       "865       24        24    True\n",
       "866       24        24    True\n",
       "...      ...       ...     ...\n",
       "9704    1793      1793    True\n",
       "9715    1793       368   False\n",
       "9716    1793      1793    True\n",
       "9718    1793       368   False\n",
       "9719    1793       368   False\n",
       "9720    1793      1793    True\n",
       "9724    1793      1793    True\n",
       "9726    1793      1793    True\n",
       "9727    1793      1793    True\n",
       "9729    1793      1793    True\n",
       "9730    1793      1793    True\n",
       "9731    1793        24   False\n",
       "9732      24      1793   False\n",
       "9734      24        24    True\n",
       "9735    1793      1793    True\n",
       "9739      24        24    True\n",
       "9740      24        24    True\n",
       "9744      24      1793   False\n",
       "9746      24        24    True\n",
       "9749      24        24    True\n",
       "9750      24        24    True\n",
       "9751      24      1793   False\n",
       "9752      24        24    True\n",
       "9753      24        24    True\n",
       "9754      24        24    True\n",
       "9755      24        24    True\n",
       "9756      24        24    True\n",
       "9757      24      1793   False\n",
       "9758      24        24    True\n",
       "9759      24      1793   False\n",
       "\n",
       "[1011 rows x 3 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_test_df = fns.result_table(xgb_true, xgb_pred)\n",
    "xgb_test_df = xgb_test_df.rename(index=str, columns={'predictions': 'xgb_pred', 'results': 'xgb_res'})\n",
    "xgb_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">xgb_res</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_pred</th>\n",
       "      <th>24</th>\n",
       "      <th>368</th>\n",
       "      <th>1793</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>271</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>43</td>\n",
       "      <td>251</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         xgb_res          \n",
       "xgb_pred    24   368  1793\n",
       "actual                    \n",
       "24           271   38   33\n",
       "368           43  251   40\n",
       "1793          36   37  262"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xgb_test_df.groupby(['actual', 'xgb_pred']).aggregate({'xgb_res': 'count'}).unstack()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  2., ...,  2.,  0.,  2.], dtype=float32)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save and load xgboost model\n",
    "best_xgb.save_model('models/xgb.model')\n",
    "\n",
    "bst = xgb.Booster({'nthread':4}) #init model\n",
    "bst.load_model(\"models/xgb.model\") # load data\n",
    "bst.predict(xgtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# PCA + XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Get 15 principal components\n",
    "xgb_pca = PCA(n_components=15)\n",
    "xgb_pca.fit(train)\n",
    "xgb_pca_transformed = pd.DataFrame(xgb_pca.transform(train))\n",
    "xgb_pca_transformed_test = pd.DataFrame(xgb_pca.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98238212024365967"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEZCAYAAACJjGL9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb84184810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xgb_pca.explained_variance_ratio_)\n",
    "plt.title(\"Scree Plot: 10 Principal Components\")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"% of Explained Variance\")\n",
    "sum(xgb_pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[46]\ttrain-mae:224.288+3.73704\ttest-mae:487.254+9.63929\n",
      "\n",
      "    1 | 00m02s | \u001b[35m-487.25399\u001b[0m | \u001b[32m   8.9361\u001b[0m | \u001b[32m            0.7714\u001b[0m | \u001b[32m   4.0923\u001b[0m | \u001b[32m    10.2920\u001b[0m | \u001b[32m            6.7094\u001b[0m | \u001b[32m     0.5110\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[66]\ttrain-mae:135.613+4.30127\ttest-mae:481.314+9.11691\n",
      "\n",
      "    2 | 00m04s | \u001b[35m-481.31410\u001b[0m | \u001b[32m   0.9600\u001b[0m | \u001b[32m            0.2547\u001b[0m | \u001b[32m   1.6254\u001b[0m | \u001b[32m    13.1474\u001b[0m | \u001b[32m           11.7408\u001b[0m | \u001b[32m     0.8134\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[118]\ttrain-mae:303.96+5.43423\ttest-mae:493.807+8.85979\n",
      "\n",
      "    3 | 00m02s | -493.80718 |    9.3435 |             0.9968 |    9.6060 |      5.7120 |             7.1943 |      0.5930 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[70]\ttrain-mae:249.155+3.75627\ttest-mae:482.907+10.7806\n",
      "\n",
      "    4 | 00m02s | -482.90692 |    3.0614 |             0.1075 |    9.4726 |     10.3039 |            17.5290 |      0.5655 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[113]\ttrain-mae:250.285+2.45921\ttest-mae:485.679+10.3874\n",
      "\n",
      "    5 | 00m03s | -485.67916 |    6.1357 |             0.7877 |    7.5091 |      7.7716 |            19.8339 |      0.6503 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[33]\ttrain-mae:147.052+1.72425\ttest-mae:486.763+10.8327\n",
      "\n",
      "    6 | 00m10s | -486.76348 |    0.0000 |             0.1000 |    0.0000 |     15.0000 |             1.0000 |      0.5000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[58]\ttrain-mae:191.901+2.89278\ttest-mae:482.7+8.74602\n",
      "\n",
      "    7 | 00m08s | -482.70013 |   10.0000 |             0.1000 |    0.0000 |     15.0000 |            20.0000 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[80]\ttrain-mae:233+3.62057\ttest-mae:485.928+8.7389\n",
      "\n",
      "    8 | 00m07s | -485.92783 |    0.0000 |             1.0000 |   10.0000 |     15.0000 |            20.0000 |      0.5000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[149]\ttrain-mae:307.909+2.37286\ttest-mae:498.176+6.76793\n",
      "\n",
      "    9 | 00m07s | -498.17574 |    0.0000 |             0.1000 |    0.0000 |      5.0000 |            20.0000 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[45]\ttrain-mae:310.339+1.72112\ttest-mae:485.852+9.20357\n",
      "\n",
      "   10 | 00m08s | -485.85157 |   10.0000 |             0.1000 |   10.0000 |     15.0000 |            20.0000 |      0.5000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[48]\ttrain-mae:18.2519+1.1805\ttest-mae:490.985+12.4014\n",
      "\n",
      "   11 | 00m10s | -490.98544 |   10.0000 |             0.1000 |    0.0000 |     15.0000 |             1.0000 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[42]\ttrain-mae:252.044+2.15185\ttest-mae:488.155+4.78564\n",
      "\n",
      "   12 | 00m06s | -488.15521 |    0.0000 |             0.1000 |    2.8733 |     15.0000 |            11.0315 |      0.5000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[180]\ttrain-mae:242.133+3.79429\ttest-mae:494.886+6.62722\n",
      "\n",
      "   13 | 00m08s | -494.88587 |    0.0000 |             1.0000 |    0.0000 |      5.0000 |             1.0000 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[87]\ttrain-mae:101.069+4.08764\ttest-mae:482.898+15.0361\n",
      "\n",
      "   14 | 00m10s | -482.89834 |    3.6770 |             1.0000 |    0.0000 |     12.3717 |            11.9203 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:88.7115+4.25768\ttest-mae:479.853+11.9928\n",
      "\n",
      "   15 | 00m10s | \u001b[35m-479.85258\u001b[0m | \u001b[32m   8.4552\u001b[0m | \u001b[32m            0.4911\u001b[0m | \u001b[32m   1.8326\u001b[0m | \u001b[32m    12.2702\u001b[0m | \u001b[32m           12.7859\u001b[0m | \u001b[32m     0.9421\u001b[0m | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:88.7115+4.25768\ttest-mae:479.853+11.9928\n",
      "\n",
      "   16 | 00m10s | -479.85258 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:88.7115+4.25768\ttest-mae:479.853+11.9928\n",
      "\n",
      "   17 | 00m10s | -479.85258 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:88.7115+4.25768\ttest-mae:479.853+11.9928\n",
      "\n",
      "   18 | 00m10s | -479.85258 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:88.7115+4.25768\ttest-mae:479.853+11.9928\n",
      "\n",
      "   19 | 00m10s | -479.85258 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:88.7115+4.25768\ttest-mae:479.853+11.9928\n",
      "\n",
      "   20 | 00m10s | -479.85258 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:88.7115+4.25768\ttest-mae:479.853+11.9928\n",
      "\n",
      "   21 | 00m10s | -479.85258 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:88.7115+4.25768\ttest-mae:479.853+11.9928\n",
      "\n",
      "   22 | 00m11s | -479.85258 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:88.7115+4.25768\ttest-mae:479.853+11.9928\n",
      "\n",
      "   23 | 00m10s | -479.85258 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:88.7115+4.25768\ttest-mae:479.853+11.9928\n",
      "\n",
      "   24 | 00m11s | -479.85258 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:88.7115+4.25768\ttest-mae:479.853+11.9928\n",
      "\n",
      "   25 | 00m10s | -479.85258 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:88.7115+4.25768\ttest-mae:479.853+11.9928\n",
      "\n",
      "   26 | 00m10s | -479.85258 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:88.7115+4.25768\ttest-mae:479.853+11.9928\n",
      "\n",
      "   27 | 00m10s | -479.85258 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:88.7115+4.25768\ttest-mae:479.853+11.9928\n",
      "\n",
      "   28 | 00m10s | -479.85258 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:88.7115+4.25768\ttest-mae:479.853+11.9928\n",
      "\n",
      "   29 | 00m10s | -479.85258 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:88.7115+4.25768\ttest-mae:479.853+11.9928\n",
      "\n",
      "   30 | 00m10s | -479.85258 |    8.4552 |             0.4911 |    1.8326 |     12.2702 |            12.7859 |      0.9421 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run BO for pca of color histogram\n",
    "if __name__ == '__main__':\n",
    "    xgtrain = prepare_data(xgb_pca_transformed, train_labels)\n",
    "    \n",
    "    num_rounds = 3000\n",
    "    random_state = 2016\n",
    "    num_iter = 25\n",
    "    init_points = 5\n",
    "    params = {\n",
    "        'eta': 0.1,\n",
    "        'silent': 1,\n",
    "        'eval_metric': 'mae',\n",
    "        'verbose_eval': True,\n",
    "        'seed': random_state\n",
    "    }\n",
    "\n",
    "    xgbBO = BayesianOptimization(xgb_evaluate, {'min_child_weight': (1, 20),\n",
    "                                                'colsample_bytree': (0.1, 1),\n",
    "                                                'max_depth': (5, 15),\n",
    "                                                'subsample': (0.5, 1),\n",
    "                                                'gamma': (0, 10),\n",
    "                                                'alpha': (0, 10),\n",
    "                                                })\n",
    "\n",
    "    xgbBO.maximize(init_points=init_points, n_iter=num_iter)\n",
    "    \n",
    "    print \"Best Params %s\" % str(xgbBO.res['max'])\n",
    "    \n",
    "    # xgtrain.get_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_params': {'alpha': 8.4552080256529223,\n",
       "  'colsample_bytree': 0.49105245763279459,\n",
       "  'gamma': 1.8325538014822962,\n",
       "  'max_depth': 12.270173863438597,\n",
       "  'min_child_weight': 12.78586493371901,\n",
       "  'subsample': 0.94208992307656025},\n",
       " 'max_val': -479.8525818}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbBO.res['max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Model on training set:0.79440870856\n",
      "Accuracy of the Model on testing set:0.71315529179\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pca_train_labels_encd, pca_test_labels_encd, pca_xgtrain, pca_xgtest = prepare_model_data(xgb_pca_transformed, \\\n",
    "                                                                                          train_labels, \\\n",
    "                                                                                          xgb_pca_transformed_test, \\\n",
    "                                                                                          test_labels)\n",
    "\n",
    "\n",
    "# Choose the best params from BO results then predict \n",
    "best_min_child_weight = 13\n",
    "best_colsample_bytree = 0.49\n",
    "best_subsample = 0.94\n",
    "best_gamma = 1.8\n",
    "best_alpha = 8.4\n",
    "best_max_depth = 12\n",
    "\n",
    "num_round = 1000\n",
    "\n",
    "params['objective'] = 'multi:softmax'\n",
    "params['num_class'] = 3\n",
    "params['eval_metric'] = \"mlogloss\"\n",
    "params['min_child_weight'] = best_min_child_weight\n",
    "params['colsample_bytree'] = best_colsample_bytree\n",
    "params['max_depth'] = best_max_depth\n",
    "params['subsample'] = best_subsample\n",
    "params['gamma'] = best_gamma\n",
    "params['alpha'] = best_alpha\n",
    "\n",
    "pca_best_xgb = xgb.train(params, pca_xgtrain, num_round)\n",
    "pca_best_xgb.save_model('models/xgb_pca.model')\n",
    "\n",
    "\n",
    "pca_best_xgb_pred = pca_best_xgb.predict(pca_xgtrain)\n",
    "# use the best params to predict\n",
    "pca_xgb_true, pca_xgb_pred_test = test_labels, pca_best_xgb.predict(pca_xgtest)\n",
    "pca_xgb_pred\n",
    "\n",
    "\n",
    "# accuracy for the train set\n",
    "print \"Accuracy of the Model on training set:\" + str(get_xgb_score(train_labels_encd, pca_best_xgb_pred))\n",
    "\n",
    "# accuracy for the test set\n",
    "print \"Accuracy of the Model on testing set:\" + str(get_xgb_score(test_labels_encd, pca_xgb_pred_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pca_best_xgb_pred = get_transformed_class(pca_best_xgb_pred)\n",
    "pca_xgb_pred_test = get_transformed_class(pca_xgb_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>xgb_pca_pred</th>\n",
       "      <th>xgb_pca_res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>24</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>24</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9715</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9716</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9718</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9720</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9726</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9727</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9729</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9730</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9731</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9732</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9734</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9735</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9746</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9749</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9752</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9753</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9756</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9757</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9758</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9759</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1011 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual  xgb_pca_pred xgb_pca_res\n",
       "33        24            24        True\n",
       "34      1793          1793        True\n",
       "35      1793          1793        True\n",
       "37      1793            24       False\n",
       "101     1793          1793        True\n",
       "102     1793          1793        True\n",
       "105     1793          1793        True\n",
       "217     1793            24       False\n",
       "261     1793          1793        True\n",
       "295     1793          1793        True\n",
       "354     1793            24       False\n",
       "355     1793            24       False\n",
       "399     1793          1793        True\n",
       "474     1793          1793        True\n",
       "507     1793          1793        True\n",
       "545     1793          1793        True\n",
       "554       24            24        True\n",
       "604       24            24        True\n",
       "607       24           368       False\n",
       "608       24            24        True\n",
       "662       24            24        True\n",
       "686     1793          1793        True\n",
       "710     1793          1793        True\n",
       "860       24           368       False\n",
       "861       24            24        True\n",
       "862       24          1793       False\n",
       "863       24            24        True\n",
       "864       24            24        True\n",
       "865       24            24        True\n",
       "866       24            24        True\n",
       "...      ...           ...         ...\n",
       "9704    1793            24       False\n",
       "9715    1793          1793        True\n",
       "9716    1793           368       False\n",
       "9718    1793            24       False\n",
       "9719    1793           368       False\n",
       "9720    1793          1793        True\n",
       "9724    1793          1793        True\n",
       "9726    1793          1793        True\n",
       "9727    1793          1793        True\n",
       "9729    1793           368       False\n",
       "9730    1793          1793        True\n",
       "9731    1793            24       False\n",
       "9732      24            24        True\n",
       "9734      24            24        True\n",
       "9735    1793          1793        True\n",
       "9739      24            24        True\n",
       "9740      24            24        True\n",
       "9744      24          1793       False\n",
       "9746      24            24        True\n",
       "9749      24            24        True\n",
       "9750      24            24        True\n",
       "9751      24          1793       False\n",
       "9752      24            24        True\n",
       "9753      24            24        True\n",
       "9754      24            24        True\n",
       "9755      24            24        True\n",
       "9756      24            24        True\n",
       "9757      24          1793       False\n",
       "9758      24            24        True\n",
       "9759      24          1793       False\n",
       "\n",
       "[1011 rows x 3 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_xgb_test_df = fns.result_table(pca_xgb_true, pca_xgb_pred_test)\n",
    "pca_xgb_test_df = pca_xgb_test_df.rename(index=str, columns={'predictions': 'xgb_pca_pred', 'results': 'xgb_pca_res'})\n",
    "pca_xgb_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">xgb_pca_res</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_pca_pred</th>\n",
       "      <th>24</th>\n",
       "      <th>368</th>\n",
       "      <th>1793</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>244</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>49</td>\n",
       "      <td>232</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             xgb_pca_res          \n",
       "xgb_pca_pred        24   368  1793\n",
       "actual                            \n",
       "24                   244   46   52\n",
       "368                   49  232   53\n",
       "1793                  43   47  245"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_xgb_test_df.groupby(['actual', 'xgb_pca_pred']).aggregate({'xgb_pca_res': 'count'}).unstack()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>xgb_pred</th>\n",
       "      <th>xgb_res</th>\n",
       "      <th>xgb_pca_pred</th>\n",
       "      <th>xgb_pca_res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340715</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340716</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340717</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340718</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340719</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340720</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340721</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340722</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340723</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340724</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340725</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340726</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340727</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340728</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340729</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340730</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340731</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340732</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340733</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340734</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340735</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340736</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340737</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340738</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340739</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340740</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340741</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340742</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340743</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340744</th>\n",
       "      <td>368</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "      <td>368</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340745 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        actual  xgb_pred xgb_res  xgb_pca_pred xgb_pca_res\n",
       "0           24        24    True            24        True\n",
       "1           24        24    True            24        True\n",
       "2           24        24    True            24        True\n",
       "3           24        24    True           368       False\n",
       "4           24        24    True            24        True\n",
       "5           24        24    True            24        True\n",
       "6           24        24    True           368       False\n",
       "7           24        24    True            24        True\n",
       "8           24        24    True          1793       False\n",
       "9           24        24    True            24        True\n",
       "10          24        24    True            24        True\n",
       "11          24        24    True            24        True\n",
       "12          24        24    True            24        True\n",
       "13          24        24    True          1793       False\n",
       "14          24        24    True           368       False\n",
       "15          24        24    True            24        True\n",
       "16          24        24    True            24        True\n",
       "17          24        24    True            24        True\n",
       "18          24        24    True            24        True\n",
       "19          24        24    True            24        True\n",
       "20          24        24    True            24        True\n",
       "21          24        24    True            24        True\n",
       "22          24        24    True            24        True\n",
       "23          24        24    True            24        True\n",
       "24          24        24    True           368       False\n",
       "25          24        24    True            24        True\n",
       "26          24        24    True            24        True\n",
       "27          24        24    True           368       False\n",
       "28          24        24    True          1793       False\n",
       "29          24        24    True            24        True\n",
       "...        ...       ...     ...           ...         ...\n",
       "340715     368       368    True           368        True\n",
       "340716     368       368    True           368        True\n",
       "340717     368       368    True           368        True\n",
       "340718     368       368    True           368        True\n",
       "340719     368       368    True           368        True\n",
       "340720     368       368    True           368        True\n",
       "340721     368       368    True            24       False\n",
       "340722     368       368    True           368        True\n",
       "340723     368       368    True           368        True\n",
       "340724     368       368    True           368        True\n",
       "340725     368       368    True           368        True\n",
       "340726     368       368    True          1793       False\n",
       "340727     368       368    True           368        True\n",
       "340728     368       368    True           368        True\n",
       "340729     368       368    True           368        True\n",
       "340730     368       368    True          1793       False\n",
       "340731     368       368    True           368        True\n",
       "340732     368       368    True          1793       False\n",
       "340733     368       368    True           368        True\n",
       "340734     368       368    True            24       False\n",
       "340735     368       368    True           368        True\n",
       "340736     368       368    True           368        True\n",
       "340737     368       368    True           368        True\n",
       "340738     368       368    True           368        True\n",
       "340739     368       368    True           368        True\n",
       "340740     368       368    True            24       False\n",
       "340741     368       368    True           368        True\n",
       "340742     368       368    True           368        True\n",
       "340743     368       368    True           368        True\n",
       "340744     368       368    True           368        True\n",
       "\n",
       "[340745 rows x 5 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_com = xgb_test_df.merge(pca_xgb_test_df, how='inner', on='actual')\n",
    "xgb_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xgb_com.to_csv('data/xgb_com.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  1., ...,  0.,  0.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save and load xgboost model\n",
    "pca_best_xgb.save_model('models/xgb_pca.model')\n",
    "\n",
    "bst_pca = xgb.Booster({'nthread':4}) #init model\n",
    "bst_pca.load_model(\"models/xgb_pca.model\") # load data\n",
    "bst_pca.predict(xgtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def xgb_evaluate(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma,\n",
    "                 alpha):\n",
    "    params = {}\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['cosample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    params['alpha'] = max(alpha, 0)\n",
    "\n",
    "    num_rounds = 3000\n",
    "    random_state = 2017\n",
    "    \n",
    "    random_state = 2017\n",
    "    \n",
    "    cv_result = cross_val_score(\n",
    "        xgb(\n",
    "                 seed=random_state,\n",
    "                 min_child_weight = int(min_child_weight),\n",
    "                 cosample_bytree = max(min(colsample_bytree, 1), 0),\n",
    "                 max_depth = int(max_depth),\n",
    "                 subsample = max(min(subsample, 1), 0),\n",
    "                 gamma = max(gamma, 0),\n",
    "                 alpha = max(alpha, 0)        \n",
    "             ),\n",
    "        train, train_labels, 'f1', cv=5\n",
    "    ).mean()\n",
    "    return cv_result\n",
    "\n",
    "\n",
    "def xgb_pca_evaluate(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma,\n",
    "                 alpha):\n",
    "\n",
    "#     params['min_child_weight'] = int(min_child_weight)\n",
    "#     params['cosample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "#     params['max_depth'] = int(max_depth)\n",
    "#     params['subsample'] = max(min(subsample, 1), 0)\n",
    "#     params['gamma'] = max(gamma, 0)\n",
    "#     params['alpha'] = max(alpha, 0)\n",
    "    \n",
    "\n",
    "    random_state = 2017\n",
    "    \n",
    "    cv_result = cross_val_score(\n",
    "        xgb(\n",
    "                 seed=random_state,\n",
    "                 min_child_weight = int(min_child_weight),\n",
    "                 cosample_bytree = max(min(colsample_bytree, 1), 0),\n",
    "                 max_depth = int(max_depth),\n",
    "                 subsample = max(min(subsample, 1), 0),\n",
    "                 gamma = max(gamma, 0),\n",
    "                 alpha = max(alpha, 0)        \n",
    "             ),\n",
    "        pca_transformed, train_labels, 'f1', cv=5\n",
    "    ).mean()\n",
    "    return cv_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def xgb_bo(xgb_fn = xgb_evaluate):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    random_state = 2017\n",
    "    num_iter = 25\n",
    "    init_points = 5\n",
    "#     params = {\n",
    "#         'eta': 0.1,\n",
    "#         'silent': 1,\n",
    "#         'eval_metric': 'mae',\n",
    "#         'verbose_eval': True,\n",
    "#         'seed': random_state\n",
    "#     }\n",
    "\n",
    "    xgbBO = BayesianOptimization(xgb_fn, {'min_child_weight': (1, 20),\n",
    "                                                'colsample_bytree': (0.1, 1),\n",
    "                                                'max_depth': (5, 15),\n",
    "                                                'subsample': (0.5, 1),\n",
    "                                                'gamma': (0, 10),\n",
    "                                                'alpha': (0, 10),\n",
    "                                                })\n",
    "\n",
    "    xgbBO.maximize(init_points=init_points, n_iter=num_iter)\n",
    "    print('-' * 53)\n",
    "    print 'Costed time: \\n%f' % (time.time() - start_time)\n",
    "\n",
    "    print('-' * 53)\n",
    "    print('Final Results')\n",
    "    print('XGboost: %f' % xgbBO.res['max']['max_val'])\n",
    "    print('-' * 53)\n",
    "    print('XGboost: %f' % xgbBO.res['max'])\n",
    "    fns.plot_bo(xgb_fn, xgbBO)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
