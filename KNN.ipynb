{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "======================================================================================================\n",
    "\n",
    "# KNN & PCA\n",
    "\n",
    "======================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athenaeum_authors_preview.csv\n",
      "athenaeum_painting_filtered.csv\n",
      "athenaeum_paintings.csv\n",
      "athenaeum_paintings_sizes.csv\n",
      "color_histograms.csv\n",
      "complete_data.csv\n",
      "extra_tree_com.csv\n",
      "grad_boost_com.csv\n",
      "images\n",
      "images_athenaeum\n",
      "images_sizes_2325.csv\n",
      "net_predicted.csv\n",
      "painter_info_clean.csv\n",
      "painting_info_clean.csv\n",
      "resized_200\n",
      "rf_com.csv\n",
      "test_author200.csv\n",
      "test_data.csv\n",
      "test_hist_author_knn.csv\n",
      "test_hist_author_rf.csv\n",
      "train_author200.csv\n",
      "train_data.csv\n",
      "train_hist_author_knn.csv\n",
      "train_hist_author_rf.csv\n",
      "xgb_com.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "# import sklearn.grid_search\n",
    "\n",
    "import fns_models as fns\n",
    "\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"data\"]).decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The size of train histogram for Random Forest(49890, 35)\n",
      "[INFO] The size of test histogram for Random Forest(12473, 35)\n",
      "24      1369\n",
      "1793    1338\n",
      "368     1335\n",
      "Name: author_id, dtype: int64\n",
      "[trian above] ==================================================[test below]\n",
      "24      342\n",
      "1793    335\n",
      "368     334\n",
      "Name: author_id, dtype: int64\n",
      "(4042,)\n",
      "(4042, 35)\n"
     ]
    }
   ],
   "source": [
    "train, train_labels, test, test_labels = fns.get_top_author(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hist_01</th>\n",
       "      <th>hist_02</th>\n",
       "      <th>hist_03</th>\n",
       "      <th>hist_04</th>\n",
       "      <th>hist_05</th>\n",
       "      <th>hist_06</th>\n",
       "      <th>hist_07</th>\n",
       "      <th>hist_08</th>\n",
       "      <th>hist_09</th>\n",
       "      <th>hist_10</th>\n",
       "      <th>...</th>\n",
       "      <th>hist_22</th>\n",
       "      <th>hist_23</th>\n",
       "      <th>hist_24</th>\n",
       "      <th>hist_25</th>\n",
       "      <th>hist_26</th>\n",
       "      <th>hist_27</th>\n",
       "      <th>hist_28</th>\n",
       "      <th>hist_29</th>\n",
       "      <th>hist_30</th>\n",
       "      <th>height_width_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.075736</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.010185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064973</td>\n",
       "      <td>0.155495</td>\n",
       "      <td>0.198439</td>\n",
       "      <td>0.022097</td>\n",
       "      <td>0.106906</td>\n",
       "      <td>0.188239</td>\n",
       "      <td>0.087873</td>\n",
       "      <td>0.033008</td>\n",
       "      <td>0.583974</td>\n",
       "      <td>1.984496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.113157</td>\n",
       "      <td>0.100789</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.004417</td>\n",
       "      <td>0.011081</td>\n",
       "      <td>0.024289</td>\n",
       "      <td>0.064011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120838</td>\n",
       "      <td>0.122384</td>\n",
       "      <td>0.240406</td>\n",
       "      <td>0.066717</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>0.036815</td>\n",
       "      <td>0.124549</td>\n",
       "      <td>0.168427</td>\n",
       "      <td>0.663395</td>\n",
       "      <td>1.565749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0.039886</td>\n",
       "      <td>0.167470</td>\n",
       "      <td>0.076083</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484468</td>\n",
       "      <td>0.307293</td>\n",
       "      <td>0.022210</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.011258</td>\n",
       "      <td>0.037837</td>\n",
       "      <td>0.110167</td>\n",
       "      <td>0.263844</td>\n",
       "      <td>0.576894</td>\n",
       "      <td>1.412414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hist_01   hist_02   hist_03   hist_04   hist_05   hist_06   hist_07  \\\n",
       "177  0.075736  0.001017  0.000195  0.000061  0.000091  0.000167  0.000124   \n",
       "381  0.113157  0.100789  0.008086  0.001295  0.001914  0.004696  0.004417   \n",
       "383  0.039886  0.167470  0.076083  0.001664  0.000785  0.000676  0.000319   \n",
       "\n",
       "      hist_08   hist_09   hist_10         ...           hist_22   hist_23  \\\n",
       "177  0.000265  0.000814  0.010185         ...          0.064973  0.155495   \n",
       "381  0.011081  0.024289  0.064011         ...          0.120838  0.122384   \n",
       "383  0.000550  0.000656  0.002208         ...          0.484468  0.307293   \n",
       "\n",
       "      hist_24   hist_25   hist_26   hist_27   hist_28   hist_29   hist_30  \\\n",
       "177  0.198439  0.022097  0.106906  0.188239  0.087873  0.033008  0.583974   \n",
       "381  0.240406  0.066717  0.006814  0.036815  0.124549  0.168427  0.663395   \n",
       "383  0.022210  0.002730  0.011258  0.037837  0.110167  0.263844  0.576894   \n",
       "\n",
       "     height_width_ratio  \n",
       "177            1.984496  \n",
       "381            1.565749  \n",
       "383            1.412414  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "======================================================================================================\n",
    "\n",
    "# KNN \n",
    "\n",
    "======================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# random.seed(2017)\n",
    "\n",
    "# X_trian, X_val, y_train, y_val = train_test_split(train, train_labels, test_size = 0.5, random_state=0)\n",
    "\n",
    "# print \"Length of Validation Set:\" + str(len(y_val))\n",
    "# print \"Length of Train Set:\" + str(len(y_train))\n",
    "# print \"Ratio: \" + str(len(y_val) / float(len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "int(math.ceil(math.sqrt(len(train))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN Model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid={'n_neighbors': [5, 10, 15, 20, 30, 40, 50, 64, 70, 80, 90, 100, 125, 200, 250], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'p': [1, 2, 9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the KNN model\n",
    "print \"Training KNN Model...\"\n",
    "\n",
    "# minkowski_distance\n",
    "k = [5, 10, 15, 20, 30, 40, 50, 64, 70, 80, 90, 100, 125, 200, 250]\n",
    "#k = [5, 20]\n",
    "parameters = {'n_neighbors': k, 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'p': [1, 2, 9]}\n",
    "knn = KNeighborsClassifier()\n",
    "clf = GridSearchCV(knn, parameters, cv=6, n_jobs=4)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Model on testing set:0.707220573689\n",
      "Accuracy of the Model on training set:0.705838693716\n"
     ]
    }
   ],
   "source": [
    "clf.fit(train, train_labels)\n",
    "# accuracy for the test set\n",
    "print \"Accuracy of the Model on testing set:\" + str(clf.score(test,test_labels))\n",
    "\n",
    "# accuracy for the train set\n",
    "print \"Accuracy of the Model on training set:\" + str(clf.score(train,train_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "()\n",
      "{'n_neighbors': 30, 'algorithm': 'auto', 'p': 1}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.644 (+/-0.040) for {'n_neighbors': 5, 'algorithm': 'auto', 'p': 1}\n",
      "0.629 (+/-0.054) for {'n_neighbors': 5, 'algorithm': 'auto', 'p': 2}\n",
      "0.602 (+/-0.049) for {'n_neighbors': 5, 'algorithm': 'auto', 'p': 9}\n",
      "0.667 (+/-0.042) for {'n_neighbors': 10, 'algorithm': 'auto', 'p': 1}\n",
      "0.648 (+/-0.056) for {'n_neighbors': 10, 'algorithm': 'auto', 'p': 2}\n",
      "0.624 (+/-0.035) for {'n_neighbors': 10, 'algorithm': 'auto', 'p': 9}\n",
      "0.672 (+/-0.037) for {'n_neighbors': 15, 'algorithm': 'auto', 'p': 1}\n",
      "0.652 (+/-0.058) for {'n_neighbors': 15, 'algorithm': 'auto', 'p': 2}\n",
      "0.633 (+/-0.037) for {'n_neighbors': 15, 'algorithm': 'auto', 'p': 9}\n",
      "0.673 (+/-0.039) for {'n_neighbors': 20, 'algorithm': 'auto', 'p': 1}\n",
      "0.657 (+/-0.048) for {'n_neighbors': 20, 'algorithm': 'auto', 'p': 2}\n",
      "0.626 (+/-0.027) for {'n_neighbors': 20, 'algorithm': 'auto', 'p': 9}\n",
      "0.675 (+/-0.041) for {'n_neighbors': 30, 'algorithm': 'auto', 'p': 1}\n",
      "0.654 (+/-0.042) for {'n_neighbors': 30, 'algorithm': 'auto', 'p': 2}\n",
      "0.624 (+/-0.045) for {'n_neighbors': 30, 'algorithm': 'auto', 'p': 9}\n",
      "0.667 (+/-0.049) for {'n_neighbors': 40, 'algorithm': 'auto', 'p': 1}\n",
      "0.650 (+/-0.049) for {'n_neighbors': 40, 'algorithm': 'auto', 'p': 2}\n",
      "0.625 (+/-0.045) for {'n_neighbors': 40, 'algorithm': 'auto', 'p': 9}\n",
      "0.669 (+/-0.049) for {'n_neighbors': 50, 'algorithm': 'auto', 'p': 1}\n",
      "0.645 (+/-0.046) for {'n_neighbors': 50, 'algorithm': 'auto', 'p': 2}\n",
      "0.624 (+/-0.047) for {'n_neighbors': 50, 'algorithm': 'auto', 'p': 9}\n",
      "0.664 (+/-0.043) for {'n_neighbors': 64, 'algorithm': 'auto', 'p': 1}\n",
      "0.645 (+/-0.035) for {'n_neighbors': 64, 'algorithm': 'auto', 'p': 2}\n",
      "0.621 (+/-0.031) for {'n_neighbors': 64, 'algorithm': 'auto', 'p': 9}\n",
      "0.665 (+/-0.042) for {'n_neighbors': 70, 'algorithm': 'auto', 'p': 1}\n",
      "0.646 (+/-0.043) for {'n_neighbors': 70, 'algorithm': 'auto', 'p': 2}\n",
      "0.618 (+/-0.036) for {'n_neighbors': 70, 'algorithm': 'auto', 'p': 9}\n",
      "0.661 (+/-0.036) for {'n_neighbors': 80, 'algorithm': 'auto', 'p': 1}\n",
      "0.644 (+/-0.038) for {'n_neighbors': 80, 'algorithm': 'auto', 'p': 2}\n",
      "0.621 (+/-0.041) for {'n_neighbors': 80, 'algorithm': 'auto', 'p': 9}\n",
      "0.662 (+/-0.036) for {'n_neighbors': 90, 'algorithm': 'auto', 'p': 1}\n",
      "0.643 (+/-0.042) for {'n_neighbors': 90, 'algorithm': 'auto', 'p': 2}\n",
      "0.616 (+/-0.036) for {'n_neighbors': 90, 'algorithm': 'auto', 'p': 9}\n",
      "0.662 (+/-0.038) for {'n_neighbors': 100, 'algorithm': 'auto', 'p': 1}\n",
      "0.639 (+/-0.043) for {'n_neighbors': 100, 'algorithm': 'auto', 'p': 2}\n",
      "0.610 (+/-0.039) for {'n_neighbors': 100, 'algorithm': 'auto', 'p': 9}\n",
      "0.661 (+/-0.032) for {'n_neighbors': 125, 'algorithm': 'auto', 'p': 1}\n",
      "0.634 (+/-0.028) for {'n_neighbors': 125, 'algorithm': 'auto', 'p': 2}\n",
      "0.606 (+/-0.045) for {'n_neighbors': 125, 'algorithm': 'auto', 'p': 9}\n",
      "0.651 (+/-0.032) for {'n_neighbors': 200, 'algorithm': 'auto', 'p': 1}\n",
      "0.619 (+/-0.034) for {'n_neighbors': 200, 'algorithm': 'auto', 'p': 2}\n",
      "0.595 (+/-0.050) for {'n_neighbors': 200, 'algorithm': 'auto', 'p': 9}\n",
      "0.642 (+/-0.035) for {'n_neighbors': 250, 'algorithm': 'auto', 'p': 1}\n",
      "0.615 (+/-0.024) for {'n_neighbors': 250, 'algorithm': 'auto', 'p': 2}\n",
      "0.586 (+/-0.053) for {'n_neighbors': 250, 'algorithm': 'auto', 'p': 9}\n",
      "0.644 (+/-0.040) for {'n_neighbors': 5, 'algorithm': 'ball_tree', 'p': 1}\n",
      "0.629 (+/-0.054) for {'n_neighbors': 5, 'algorithm': 'ball_tree', 'p': 2}\n",
      "0.602 (+/-0.049) for {'n_neighbors': 5, 'algorithm': 'ball_tree', 'p': 9}\n",
      "0.667 (+/-0.042) for {'n_neighbors': 10, 'algorithm': 'ball_tree', 'p': 1}\n",
      "0.648 (+/-0.056) for {'n_neighbors': 10, 'algorithm': 'ball_tree', 'p': 2}\n",
      "0.624 (+/-0.035) for {'n_neighbors': 10, 'algorithm': 'ball_tree', 'p': 9}\n",
      "0.672 (+/-0.037) for {'n_neighbors': 15, 'algorithm': 'ball_tree', 'p': 1}\n",
      "0.652 (+/-0.058) for {'n_neighbors': 15, 'algorithm': 'ball_tree', 'p': 2}\n",
      "0.633 (+/-0.037) for {'n_neighbors': 15, 'algorithm': 'ball_tree', 'p': 9}\n",
      "0.673 (+/-0.039) for {'n_neighbors': 20, 'algorithm': 'ball_tree', 'p': 1}\n",
      "0.657 (+/-0.048) for {'n_neighbors': 20, 'algorithm': 'ball_tree', 'p': 2}\n",
      "0.626 (+/-0.027) for {'n_neighbors': 20, 'algorithm': 'ball_tree', 'p': 9}\n",
      "0.675 (+/-0.041) for {'n_neighbors': 30, 'algorithm': 'ball_tree', 'p': 1}\n",
      "0.654 (+/-0.042) for {'n_neighbors': 30, 'algorithm': 'ball_tree', 'p': 2}\n",
      "0.624 (+/-0.045) for {'n_neighbors': 30, 'algorithm': 'ball_tree', 'p': 9}\n",
      "0.667 (+/-0.049) for {'n_neighbors': 40, 'algorithm': 'ball_tree', 'p': 1}\n",
      "0.650 (+/-0.049) for {'n_neighbors': 40, 'algorithm': 'ball_tree', 'p': 2}\n",
      "0.625 (+/-0.045) for {'n_neighbors': 40, 'algorithm': 'ball_tree', 'p': 9}\n",
      "0.669 (+/-0.049) for {'n_neighbors': 50, 'algorithm': 'ball_tree', 'p': 1}\n",
      "0.645 (+/-0.046) for {'n_neighbors': 50, 'algorithm': 'ball_tree', 'p': 2}\n",
      "0.624 (+/-0.047) for {'n_neighbors': 50, 'algorithm': 'ball_tree', 'p': 9}\n",
      "0.664 (+/-0.043) for {'n_neighbors': 64, 'algorithm': 'ball_tree', 'p': 1}\n",
      "0.645 (+/-0.035) for {'n_neighbors': 64, 'algorithm': 'ball_tree', 'p': 2}\n",
      "0.621 (+/-0.031) for {'n_neighbors': 64, 'algorithm': 'ball_tree', 'p': 9}\n",
      "0.665 (+/-0.042) for {'n_neighbors': 70, 'algorithm': 'ball_tree', 'p': 1}\n",
      "0.646 (+/-0.043) for {'n_neighbors': 70, 'algorithm': 'ball_tree', 'p': 2}\n",
      "0.618 (+/-0.036) for {'n_neighbors': 70, 'algorithm': 'ball_tree', 'p': 9}\n",
      "0.661 (+/-0.036) for {'n_neighbors': 80, 'algorithm': 'ball_tree', 'p': 1}\n",
      "0.644 (+/-0.038) for {'n_neighbors': 80, 'algorithm': 'ball_tree', 'p': 2}\n",
      "0.621 (+/-0.041) for {'n_neighbors': 80, 'algorithm': 'ball_tree', 'p': 9}\n",
      "0.662 (+/-0.036) for {'n_neighbors': 90, 'algorithm': 'ball_tree', 'p': 1}\n",
      "0.643 (+/-0.042) for {'n_neighbors': 90, 'algorithm': 'ball_tree', 'p': 2}\n",
      "0.616 (+/-0.036) for {'n_neighbors': 90, 'algorithm': 'ball_tree', 'p': 9}\n",
      "0.662 (+/-0.038) for {'n_neighbors': 100, 'algorithm': 'ball_tree', 'p': 1}\n",
      "0.639 (+/-0.043) for {'n_neighbors': 100, 'algorithm': 'ball_tree', 'p': 2}\n",
      "0.610 (+/-0.039) for {'n_neighbors': 100, 'algorithm': 'ball_tree', 'p': 9}\n",
      "0.661 (+/-0.032) for {'n_neighbors': 125, 'algorithm': 'ball_tree', 'p': 1}\n",
      "0.634 (+/-0.028) for {'n_neighbors': 125, 'algorithm': 'ball_tree', 'p': 2}\n",
      "0.606 (+/-0.045) for {'n_neighbors': 125, 'algorithm': 'ball_tree', 'p': 9}\n",
      "0.651 (+/-0.032) for {'n_neighbors': 200, 'algorithm': 'ball_tree', 'p': 1}\n",
      "0.619 (+/-0.034) for {'n_neighbors': 200, 'algorithm': 'ball_tree', 'p': 2}\n",
      "0.595 (+/-0.050) for {'n_neighbors': 200, 'algorithm': 'ball_tree', 'p': 9}\n",
      "0.642 (+/-0.035) for {'n_neighbors': 250, 'algorithm': 'ball_tree', 'p': 1}\n",
      "0.615 (+/-0.024) for {'n_neighbors': 250, 'algorithm': 'ball_tree', 'p': 2}\n",
      "0.586 (+/-0.053) for {'n_neighbors': 250, 'algorithm': 'ball_tree', 'p': 9}\n",
      "0.644 (+/-0.040) for {'n_neighbors': 5, 'algorithm': 'kd_tree', 'p': 1}\n",
      "0.629 (+/-0.054) for {'n_neighbors': 5, 'algorithm': 'kd_tree', 'p': 2}\n",
      "0.602 (+/-0.049) for {'n_neighbors': 5, 'algorithm': 'kd_tree', 'p': 9}\n",
      "0.667 (+/-0.042) for {'n_neighbors': 10, 'algorithm': 'kd_tree', 'p': 1}\n",
      "0.648 (+/-0.056) for {'n_neighbors': 10, 'algorithm': 'kd_tree', 'p': 2}\n",
      "0.624 (+/-0.035) for {'n_neighbors': 10, 'algorithm': 'kd_tree', 'p': 9}\n",
      "0.672 (+/-0.037) for {'n_neighbors': 15, 'algorithm': 'kd_tree', 'p': 1}\n",
      "0.652 (+/-0.058) for {'n_neighbors': 15, 'algorithm': 'kd_tree', 'p': 2}\n",
      "0.633 (+/-0.037) for {'n_neighbors': 15, 'algorithm': 'kd_tree', 'p': 9}\n",
      "0.673 (+/-0.039) for {'n_neighbors': 20, 'algorithm': 'kd_tree', 'p': 1}\n",
      "0.657 (+/-0.048) for {'n_neighbors': 20, 'algorithm': 'kd_tree', 'p': 2}\n",
      "0.626 (+/-0.027) for {'n_neighbors': 20, 'algorithm': 'kd_tree', 'p': 9}\n",
      "0.675 (+/-0.041) for {'n_neighbors': 30, 'algorithm': 'kd_tree', 'p': 1}\n",
      "0.654 (+/-0.042) for {'n_neighbors': 30, 'algorithm': 'kd_tree', 'p': 2}\n",
      "0.624 (+/-0.045) for {'n_neighbors': 30, 'algorithm': 'kd_tree', 'p': 9}\n",
      "0.667 (+/-0.049) for {'n_neighbors': 40, 'algorithm': 'kd_tree', 'p': 1}\n",
      "0.650 (+/-0.049) for {'n_neighbors': 40, 'algorithm': 'kd_tree', 'p': 2}\n",
      "0.625 (+/-0.045) for {'n_neighbors': 40, 'algorithm': 'kd_tree', 'p': 9}\n",
      "0.669 (+/-0.049) for {'n_neighbors': 50, 'algorithm': 'kd_tree', 'p': 1}\n",
      "0.645 (+/-0.046) for {'n_neighbors': 50, 'algorithm': 'kd_tree', 'p': 2}\n",
      "0.624 (+/-0.047) for {'n_neighbors': 50, 'algorithm': 'kd_tree', 'p': 9}\n",
      "0.664 (+/-0.043) for {'n_neighbors': 64, 'algorithm': 'kd_tree', 'p': 1}\n",
      "0.645 (+/-0.035) for {'n_neighbors': 64, 'algorithm': 'kd_tree', 'p': 2}\n",
      "0.621 (+/-0.031) for {'n_neighbors': 64, 'algorithm': 'kd_tree', 'p': 9}\n",
      "0.665 (+/-0.042) for {'n_neighbors': 70, 'algorithm': 'kd_tree', 'p': 1}\n",
      "0.646 (+/-0.043) for {'n_neighbors': 70, 'algorithm': 'kd_tree', 'p': 2}\n",
      "0.618 (+/-0.036) for {'n_neighbors': 70, 'algorithm': 'kd_tree', 'p': 9}\n",
      "0.661 (+/-0.036) for {'n_neighbors': 80, 'algorithm': 'kd_tree', 'p': 1}\n",
      "0.644 (+/-0.038) for {'n_neighbors': 80, 'algorithm': 'kd_tree', 'p': 2}\n",
      "0.621 (+/-0.041) for {'n_neighbors': 80, 'algorithm': 'kd_tree', 'p': 9}\n",
      "0.662 (+/-0.036) for {'n_neighbors': 90, 'algorithm': 'kd_tree', 'p': 1}\n",
      "0.643 (+/-0.042) for {'n_neighbors': 90, 'algorithm': 'kd_tree', 'p': 2}\n",
      "0.616 (+/-0.036) for {'n_neighbors': 90, 'algorithm': 'kd_tree', 'p': 9}\n",
      "0.662 (+/-0.038) for {'n_neighbors': 100, 'algorithm': 'kd_tree', 'p': 1}\n",
      "0.639 (+/-0.043) for {'n_neighbors': 100, 'algorithm': 'kd_tree', 'p': 2}\n",
      "0.610 (+/-0.039) for {'n_neighbors': 100, 'algorithm': 'kd_tree', 'p': 9}\n",
      "0.661 (+/-0.032) for {'n_neighbors': 125, 'algorithm': 'kd_tree', 'p': 1}\n",
      "0.634 (+/-0.028) for {'n_neighbors': 125, 'algorithm': 'kd_tree', 'p': 2}\n",
      "0.606 (+/-0.045) for {'n_neighbors': 125, 'algorithm': 'kd_tree', 'p': 9}\n",
      "0.651 (+/-0.032) for {'n_neighbors': 200, 'algorithm': 'kd_tree', 'p': 1}\n",
      "0.619 (+/-0.034) for {'n_neighbors': 200, 'algorithm': 'kd_tree', 'p': 2}\n",
      "0.595 (+/-0.050) for {'n_neighbors': 200, 'algorithm': 'kd_tree', 'p': 9}\n",
      "0.642 (+/-0.035) for {'n_neighbors': 250, 'algorithm': 'kd_tree', 'p': 1}\n",
      "0.615 (+/-0.024) for {'n_neighbors': 250, 'algorithm': 'kd_tree', 'p': 2}\n",
      "0.586 (+/-0.053) for {'n_neighbors': 250, 'algorithm': 'kd_tree', 'p': 9}\n",
      "0.644 (+/-0.040) for {'n_neighbors': 5, 'algorithm': 'brute', 'p': 1}\n",
      "0.629 (+/-0.054) for {'n_neighbors': 5, 'algorithm': 'brute', 'p': 2}\n",
      "0.602 (+/-0.049) for {'n_neighbors': 5, 'algorithm': 'brute', 'p': 9}\n",
      "0.667 (+/-0.042) for {'n_neighbors': 10, 'algorithm': 'brute', 'p': 1}\n",
      "0.648 (+/-0.056) for {'n_neighbors': 10, 'algorithm': 'brute', 'p': 2}\n",
      "0.624 (+/-0.035) for {'n_neighbors': 10, 'algorithm': 'brute', 'p': 9}\n",
      "0.672 (+/-0.037) for {'n_neighbors': 15, 'algorithm': 'brute', 'p': 1}\n",
      "0.652 (+/-0.058) for {'n_neighbors': 15, 'algorithm': 'brute', 'p': 2}\n",
      "0.633 (+/-0.037) for {'n_neighbors': 15, 'algorithm': 'brute', 'p': 9}\n",
      "0.673 (+/-0.039) for {'n_neighbors': 20, 'algorithm': 'brute', 'p': 1}\n",
      "0.657 (+/-0.048) for {'n_neighbors': 20, 'algorithm': 'brute', 'p': 2}\n",
      "0.626 (+/-0.027) for {'n_neighbors': 20, 'algorithm': 'brute', 'p': 9}\n",
      "0.675 (+/-0.041) for {'n_neighbors': 30, 'algorithm': 'brute', 'p': 1}\n",
      "0.654 (+/-0.042) for {'n_neighbors': 30, 'algorithm': 'brute', 'p': 2}\n",
      "0.624 (+/-0.045) for {'n_neighbors': 30, 'algorithm': 'brute', 'p': 9}\n",
      "0.667 (+/-0.049) for {'n_neighbors': 40, 'algorithm': 'brute', 'p': 1}\n",
      "0.650 (+/-0.049) for {'n_neighbors': 40, 'algorithm': 'brute', 'p': 2}\n",
      "0.625 (+/-0.045) for {'n_neighbors': 40, 'algorithm': 'brute', 'p': 9}\n",
      "0.669 (+/-0.049) for {'n_neighbors': 50, 'algorithm': 'brute', 'p': 1}\n",
      "0.645 (+/-0.046) for {'n_neighbors': 50, 'algorithm': 'brute', 'p': 2}\n",
      "0.624 (+/-0.047) for {'n_neighbors': 50, 'algorithm': 'brute', 'p': 9}\n",
      "0.664 (+/-0.043) for {'n_neighbors': 64, 'algorithm': 'brute', 'p': 1}\n",
      "0.645 (+/-0.035) for {'n_neighbors': 64, 'algorithm': 'brute', 'p': 2}\n",
      "0.621 (+/-0.031) for {'n_neighbors': 64, 'algorithm': 'brute', 'p': 9}\n",
      "0.665 (+/-0.042) for {'n_neighbors': 70, 'algorithm': 'brute', 'p': 1}\n",
      "0.646 (+/-0.043) for {'n_neighbors': 70, 'algorithm': 'brute', 'p': 2}\n",
      "0.618 (+/-0.036) for {'n_neighbors': 70, 'algorithm': 'brute', 'p': 9}\n",
      "0.661 (+/-0.036) for {'n_neighbors': 80, 'algorithm': 'brute', 'p': 1}\n",
      "0.644 (+/-0.038) for {'n_neighbors': 80, 'algorithm': 'brute', 'p': 2}\n",
      "0.621 (+/-0.041) for {'n_neighbors': 80, 'algorithm': 'brute', 'p': 9}\n",
      "0.662 (+/-0.036) for {'n_neighbors': 90, 'algorithm': 'brute', 'p': 1}\n",
      "0.643 (+/-0.042) for {'n_neighbors': 90, 'algorithm': 'brute', 'p': 2}\n",
      "0.616 (+/-0.036) for {'n_neighbors': 90, 'algorithm': 'brute', 'p': 9}\n",
      "0.662 (+/-0.038) for {'n_neighbors': 100, 'algorithm': 'brute', 'p': 1}\n",
      "0.639 (+/-0.043) for {'n_neighbors': 100, 'algorithm': 'brute', 'p': 2}\n",
      "0.610 (+/-0.039) for {'n_neighbors': 100, 'algorithm': 'brute', 'p': 9}\n",
      "0.661 (+/-0.032) for {'n_neighbors': 125, 'algorithm': 'brute', 'p': 1}\n",
      "0.634 (+/-0.028) for {'n_neighbors': 125, 'algorithm': 'brute', 'p': 2}\n",
      "0.606 (+/-0.045) for {'n_neighbors': 125, 'algorithm': 'brute', 'p': 9}\n",
      "0.651 (+/-0.032) for {'n_neighbors': 200, 'algorithm': 'brute', 'p': 1}\n",
      "0.619 (+/-0.034) for {'n_neighbors': 200, 'algorithm': 'brute', 'p': 2}\n",
      "0.595 (+/-0.050) for {'n_neighbors': 200, 'algorithm': 'brute', 'p': 9}\n",
      "0.642 (+/-0.035) for {'n_neighbors': 250, 'algorithm': 'brute', 'p': 1}\n",
      "0.615 (+/-0.024) for {'n_neighbors': 250, 'algorithm': 'brute', 'p': 2}\n",
      "0.586 (+/-0.053) for {'n_neighbors': 250, 'algorithm': 'brute', 'p': 9}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         24       0.72      0.73      0.72       342\n",
      "        368       0.68      0.75      0.71       334\n",
      "       1793       0.73      0.64      0.68       335\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1011\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = test_labels, clf.best_estimator_.predict(test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "\n",
    "# n_neighbors': 30, 'algorithm': 'auto', 'p': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  24, 1793, 1793, ..., 1793,   24, 1793])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>knn_pred</th>\n",
       "      <th>knn_res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>24</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>24</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9715</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9716</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9718</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9720</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9726</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9727</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9729</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9730</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9731</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9732</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9734</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9735</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9746</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9749</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9752</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9753</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9756</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9757</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9758</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9759</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1011 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual  knn_pred knn_res\n",
       "33        24        24    True\n",
       "34      1793      1793    True\n",
       "35      1793      1793    True\n",
       "37      1793        24   False\n",
       "101     1793       368   False\n",
       "102     1793      1793    True\n",
       "105     1793      1793    True\n",
       "217     1793        24   False\n",
       "261     1793      1793    True\n",
       "295     1793       368   False\n",
       "354     1793       368   False\n",
       "355     1793        24   False\n",
       "399     1793      1793    True\n",
       "474     1793      1793    True\n",
       "507     1793       368   False\n",
       "545     1793      1793    True\n",
       "554       24        24    True\n",
       "604       24        24    True\n",
       "607       24       368   False\n",
       "608       24        24    True\n",
       "662       24        24    True\n",
       "686     1793      1793    True\n",
       "710     1793      1793    True\n",
       "860       24       368   False\n",
       "861       24        24    True\n",
       "862       24      1793   False\n",
       "863       24        24    True\n",
       "864       24        24    True\n",
       "865       24        24    True\n",
       "866       24        24    True\n",
       "...      ...       ...     ...\n",
       "9704    1793      1793    True\n",
       "9715    1793       368   False\n",
       "9716    1793       368   False\n",
       "9718    1793        24   False\n",
       "9719    1793       368   False\n",
       "9720    1793      1793    True\n",
       "9724    1793      1793    True\n",
       "9726    1793      1793    True\n",
       "9727    1793      1793    True\n",
       "9729    1793        24   False\n",
       "9730    1793      1793    True\n",
       "9731    1793        24   False\n",
       "9732      24        24    True\n",
       "9734      24        24    True\n",
       "9735    1793      1793    True\n",
       "9739      24        24    True\n",
       "9740      24        24    True\n",
       "9744      24      1793   False\n",
       "9746      24        24    True\n",
       "9749      24        24    True\n",
       "9750      24        24    True\n",
       "9751      24        24    True\n",
       "9752      24        24    True\n",
       "9753      24        24    True\n",
       "9754      24        24    True\n",
       "9755      24        24    True\n",
       "9756      24        24    True\n",
       "9757      24      1793   False\n",
       "9758      24        24    True\n",
       "9759      24      1793   False\n",
       "\n",
       "[1011 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_test_df = fns.result_table(y_true, y_pred)\n",
    "knn_test_df = knn_test_df.rename(index=str, columns={'predictions': 'knn_pred', 'results': 'knn_res'})\n",
    "knn_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">knn_res</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_pred</th>\n",
       "      <th>24</th>\n",
       "      <th>368</th>\n",
       "      <th>1793</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>248</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>49</td>\n",
       "      <td>252</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>49</td>\n",
       "      <td>71</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         knn_res          \n",
       "knn_pred    24   368  1793\n",
       "actual                    \n",
       "24           248   49   45\n",
       "368           49  252   33\n",
       "1793          49   71  215"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "knn_test_df.groupby(['actual', 'knn_pred']).aggregate({'knn_res': 'count'}).unstack()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.707220573689\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'models/knn.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_knn_pca = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_knn_pca.score(test, test_labels)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29277942631058357"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "results.insert(0,'actual',test_labels)\n",
    "results.insert(1,'predictions',y_pred)\n",
    "\n",
    "misclassified = (results['actual'] != results['predictions']).mean()\n",
    "misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Give me the 5 nearest neighbors of the first two items in the validation set\n",
    "pd.concat((test_labels.iloc[:5].reset_index(drop = True), \n",
    "           pd.DataFrame(clf.kneighbors(test[0:5], n_neighbors=3, return_distance=False)).\n",
    "        applymap(lambda x: fn_train.iloc[x])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get neighbors \n",
    "prediction_nearest_neighbors = pd.DataFrame(clf.kneighbors(test, n_neighbors=107, return_distance=False))\n",
    "prediction_nearest_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nearest_neighbors = list(model.kneighbors(test_data_img[5], n_neighbors=31, return_distance=False)[0])\n",
    "NN_images = [y_train.iloc[x] for x in nearest_neighbors]\n",
    "[ (i,NN_images.count(i)) for i in set(NN_images) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "======================================================================================================\n",
    "\n",
    "# PCA\n",
    "\n",
    "======================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Get 10 principal components\n",
    "pca = PCA(n_components=15)\n",
    "pca.fit(train)\n",
    "pca_transformed = pca.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97650450836418023"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEZCAYAAACJjGL9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns5KcKMzMrCQnCjMzK8mJwszMSvp/BaHgtk09yv8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fab19b8c6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.title(\"Scree Plot: 10 Principal Components\")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"% of Explained Variance\")\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "======================================================================================================\n",
    "\n",
    "# KNN + PCA\n",
    "\n",
    "======================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN Model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid={'n_neighbors': [2, 3, 4, 5, 10, 15, 20], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'p': [1, 2, 9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the KNN model\n",
    "print \"Training KNN Model...\"\n",
    "\n",
    "# minkowski_distance\n",
    "k = [2, 3, 4, 5, 10, 15, 20]\n",
    "#k = [5, 20]\n",
    "parameters = {'n_neighbors': k, 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'p': [1, 2, 9]\n",
    "              }\n",
    "knn_pca = KNeighborsClassifier()\n",
    "clf_pca = GridSearchCV(knn_pca, parameters, cv=6, n_jobs=4)\n",
    "clf_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid={'n_neighbors': [2, 3, 4, 5, 10, 15, 20], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'p': [1, 2, 9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "clf_pca.fit(pca_transformed, train_labels)\n",
    "\n",
    "print('-' * 53)\n",
    "print 'Costed time: \\n%f' % (time.time() - start_time)\n",
    "\n",
    "\n",
    "# accuracy for the train set\n",
    "print \"Accuracy of the Model on training set:\" + str(clf.score(pca_transformed,train_labels))\n",
    "\n",
    "# accuracy for the test set\n",
    "print \"Accuracy of the Model on testing set:\" + str(clf.score(pca_transformed_test,test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "()\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clf_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-e8a424a90098>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters set found on development set:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Grid scores on development set:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf_pca' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf_pca.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf_pca.cv_results_['mean_test_score']\n",
    "stds = clf_pca.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf_pca.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_pca_true, y_pca_pred = test_labels, clf_pca.best_estimator_.predict(test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pca_knn_test_df = fns.result_table(knn_pca_true, knn_pca_pred)\n",
    "pca_knn_test_df = pca_knn_test_df.rename(index=str, columns={'predictions': 'knn_pca_pred', 'results': 'knn_pca_res'})\n",
    "pca_knn_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pca_knn_test_df.groupby(['actual', 'knn_pca_pred']).aggregate({'knn_pca_res': 'count'}).unstack()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "knn_com = knn_test_data_df.merge(pca_knn_test_df, how='inner', on='actual')\n",
    "knn_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "knn_com.to_csv('data/knn_com.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
