{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "============================================================================================\n",
    "\n",
    "# Extra Tree\n",
    "\n",
    "\n",
    "============================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athenaeum_authors_preview.csv\n",
      "athenaeum_painting_filtered.csv\n",
      "athenaeum_paintings.csv\n",
      "athenaeum_paintings_sizes.csv\n",
      "color_histograms.csv\n",
      "complete_data.csv\n",
      "images\n",
      "images_athenaeum\n",
      "images_sizes_2325.csv\n",
      "net_predicted.csv\n",
      "painter_info_clean.csv\n",
      "painting_info_clean.csv\n",
      "resized_200\n",
      "test_author200.csv\n",
      "test_data.csv\n",
      "test_hist_author_knn.csv\n",
      "test_hist_author_rf.csv\n",
      "train_author200.csv\n",
      "train_data.csv\n",
      "train_hist_author_knn.csv\n",
      "train_hist_author_rf.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import fns_models as fns\n",
    "\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"data\"]).decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The size of train histogram for Random Forest(49890, 34)\n",
      "[INFO] The size of test histogram for Random Forest(12473, 34)\n",
      "24      1369\n",
      "1793    1338\n",
      "368     1335\n",
      "Name: author_id, dtype: int64\n",
      "[trian above] ==================================================[test below]\n",
      "24      342\n",
      "1793    335\n",
      "368     334\n",
      "Name: author_id, dtype: int64\n",
      "(4042,)\n",
      "(4042, 34)\n"
     ]
    }
   ],
   "source": [
    "train, train_labels, test, test_labels = fns.get_top_author(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do not run it \n",
    "train = train.sample(10)\n",
    "test = test.sample(7)\n",
    "train_labels = train_labels.sample(10)\n",
    "test_labels = test_labels.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "================================================================================================================\n",
    "\n",
    "# Bayesian Optimization + Extra Tree\n",
    "\n",
    "[bayesian-optimization](https://github.com/fmfn/BayesianOptimization/blob/master/bayes_opt/bayesian_optimization.py)\n",
    "\n",
    "================================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extr_evaluate(max_features, max_depth, n_estimators):\n",
    "    \n",
    "    random.seed(2017)\n",
    "#     params['max_features'] = int(max_features)\n",
    "#     params['max_depth'] = int(max_depth)\n",
    "#     params['n_estimators'] = int(n_estimators)\n",
    "    \n",
    "    extrc = ExtraTreesClassifier(n_jobs = 4, n_estimators=int(n_estimators), oob_score=True,\n",
    "                                max_depth = int(max_depth), max_features = int(max_features),\n",
    "                                random_state = 2017, bootstrap=True)\n",
    "    #scores = cross_val_score(extrc, X=train, y = train_labels, cv=5, n_jobs = 2)\n",
    "    \n",
    "    # The mean score and the 95% confidence interval of the score estimate are hence given by:\n",
    "    #print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    #return scores.mean()\n",
    "    extrc.fit(train, train_labels)\n",
    "    return extrc.oob_score_\n",
    "\n",
    "def extr_pca_evaluate(max_features,\n",
    "                    max_depth,\n",
    "                    n_estimators):\n",
    "    \n",
    "    \n",
    "    extrc = ExtraTreesClassifier(n_jobs = 4, n_estimators=int(n_estimators), oob_score=True,\n",
    "                                max_depth = int(max_depth), max_features = int(max_features),\n",
    "                                random_state = 2017, bootstrap=True)\n",
    "    \n",
    "    extrc.fit(pca_transformed, train_labels)\n",
    "    return extrc.oob_score_\n",
    "\n",
    "def extr_bo(extr_fnc=extr_evaluate):\n",
    "    start_time = time.time()\n",
    "    num_iter = 25\n",
    "    init_points = 5\n",
    "    random_state = 2017\n",
    "    # params = {\n",
    "    #     #'eta': 0.1,\n",
    "    #     #'silent': 1,\n",
    "    #     'eval_metric': 'mae',\n",
    "    #     'verbose_eval': True,\n",
    "    #     #'seed': random_state\n",
    "    # }\n",
    "\n",
    "    extrBO = BayesianOptimization(extr_fnc, {'max_features': (5, 7),\n",
    "                                             'max_depth': (2, 7),\n",
    "                                             'n_estimators': (100, 900)})\n",
    "\n",
    "    extrBO.maximize(init_points=init_points, n_iter=num_iter)\n",
    "    \n",
    "    print('-' * 53)\n",
    "    print '\\n%f' % (time.time() - start_time)\n",
    "    \n",
    "    print \"Bayesian Optimization Best Score: %d\" % extrBO.res['max']['max_val']\n",
    "\n",
    "    print \"Bayesian Optimization Best Parameters: %s\" % str(extrBO.res['max']['max_params'])\n",
    "    \n",
    "    print (extrBO.res['max'])\n",
    "    \n",
    "#     fns.plot_bo(extr_fnc, extrBO)\n",
    "\n",
    "#     print \"Bayesian Optimization  Parameters: %s\" % str(extrBO.res['all'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   max_features |   n_estimators | \n",
      "    1 | 00m01s | \u001b[35m   0.63978\u001b[0m | \u001b[32m     5.9959\u001b[0m | \u001b[32m        6.5949\u001b[0m | \u001b[32m      387.6933\u001b[0m | \n",
      "    2 | 00m01s | \u001b[35m   0.66700\u001b[0m | \u001b[32m     9.4831\u001b[0m | \u001b[32m        5.4508\u001b[0m | \u001b[32m      248.9311\u001b[0m | \n",
      "    3 | 00m03s | \u001b[35m   0.67467\u001b[0m | \u001b[32m     9.5938\u001b[0m | \u001b[32m        6.5803\u001b[0m | \u001b[32m      820.3952\u001b[0m | \n",
      "    4 | 00m01s |    0.62840 |      4.9289 |         5.4437 |       494.8356 | \n",
      "    5 | 00m02s |    0.65710 |      7.2597 |         6.4230 |       776.1727 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   max_features |   n_estimators | \n",
      "    6 | 00m09s |    0.60391 |      2.0850 |         5.8327 |       100.0313 | \n",
      "    7 | 00m07s |    0.60861 |      2.1468 |         6.1698 |       899.9912 | \n",
      "    8 | 00m06s |    0.67417 |      9.9866 |         6.5324 |       633.9424 | \n",
      "    9 | 00m05s |    0.67170 |     10.0000 |         6.9557 |       308.5611 | \n",
      "   10 | 00m06s |    0.67244 |      9.9810 |         5.3092 |       687.9647 | \n",
      "   11 | 00m06s |    0.60787 |      2.0380 |         5.2584 |       282.9635 | \n",
      "   12 | 00m05s |    0.67368 |     10.0000 |         7.0000 |       174.6206 | \n",
      "   13 | 00m07s |    0.67442 |      9.9941 |         6.3177 |       569.9924 | \n",
      "   14 | 00m05s |    0.66749 |      9.9650 |         6.9850 |       213.5581 | \n",
      "   15 | 00m06s |    0.67120 |      9.9874 |         5.3540 |       347.5968 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  1.13257467e-05]), 'nit': 3, 'funcalls': 45}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   16 | 00m08s |    0.67442 |      9.9658 |         6.8246 |       724.2127 | \n",
      "   17 | 00m07s | \u001b[35m   0.67566\u001b[0m | \u001b[32m     9.9812\u001b[0m | \u001b[32m        6.8416\u001b[0m | \u001b[32m      434.7020\u001b[0m | \n",
      "   18 | 00m08s |    0.67368 |      9.9863 |         5.0986 |       598.4945 | \n",
      "   19 | 00m09s |    0.67343 |      9.9601 |         6.6159 |       851.0331 | \n",
      "   20 | 00m06s |    0.66675 |      9.9880 |         6.9376 |       143.6844 | \n",
      "   21 | 00m08s | \u001b[35m   0.67640\u001b[0m | \u001b[32m     9.9525\u001b[0m | \u001b[32m        6.9360\u001b[0m | \u001b[32m      536.4571\u001b[0m | \n",
      "   22 | 00m11s |    0.67566 |      9.9513 |         6.7791 |       660.5319 | \n",
      "   23 | 00m11s |    0.66972 |      9.9886 |         5.0779 |       745.9886 | \n",
      "   24 | 00m11s |    0.67541 |      9.9925 |         6.6507 |       456.0467 | \n",
      "   25 | 00m14s |    0.67417 |      9.9771 |         6.6955 |       800.7933 | \n",
      "   26 | 00m13s |    0.67293 |      9.9632 |         5.1087 |       549.6350 | \n",
      "   27 | 00m14s |    0.67615 |      9.9436 |         6.8827 |       612.8869 | \n",
      "   28 | 00m12s |    0.67145 |      9.9737 |         6.9773 |       331.9894 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  4.37370127e-05]), 'nit': 6, 'funcalls': 60}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29 | 00m14s |    0.67442 |      9.9569 |         6.9547 |       831.5898 | \n",
      "   30 | 00m14s | \u001b[35m   0.67665\u001b[0m | \u001b[32m     9.9664\u001b[0m | \u001b[32m        6.9875\u001b[0m | \u001b[32m      416.6458\u001b[0m | \n",
      "-----------------------------------------------------\n",
      "\n",
      "246.496984\n",
      "Bayesian Optimization Best Score: 0\n",
      "Bayesian Optimization Best Parameters: {'max_features': 6.987536036161984, 'n_estimators': 416.64582986125163, 'max_depth': 9.9664012155221933}\n",
      "{'max_val': 0.67664522513607128, 'max_params': {'max_features': 6.987536036161984, 'n_estimators': 416.64582986125163, 'max_depth': 9.9664012155221933}}\n"
     ]
    }
   ],
   "source": [
    "# Run BO for color histogram\n",
    "extr_bo(extr_evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of best Extra Tree model on train: 0.690747154874\n",
      "Accuracy of best Extra Tree model on test: 0.671612265084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  24, 1793, 1793, ..., 1793,   24, 1793])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the best params from BO results then predict \n",
    "best_estimators = 416\n",
    "best_max_depth = 6\n",
    "best_max_features = 7\n",
    "best_extrc = ExtraTreesClassifier(n_jobs = 4, n_estimators=best_estimators, oob_score=False,\n",
    "                                max_depth = best_max_depth, max_features = best_max_features)\n",
    "\n",
    "best_extrc.fit(train, train_labels)\n",
    "\n",
    "\n",
    "# accuracy of trianing dataset\n",
    "print \"Accuracy of best Extra Tree model on train: %s\" % str(best_extrc.score(train, train_labels))\n",
    "\n",
    "# accuracy of testing dataset\n",
    "print \"Accuracy of best Extra Tree model on test: %s\" % str(best_extrc.score(test, test_labels))\n",
    "\n",
    "\n",
    "# use the best params to predict\n",
    "extrc_true, extrc_pred = test_labels, best_extrc.predict(test)\n",
    "extrc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predictions</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>24</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>24</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9715</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9716</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9718</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9720</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9726</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9727</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9729</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9730</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9731</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9732</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9734</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9735</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9746</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9749</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9752</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9753</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9756</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9757</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9758</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9759</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1011 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual  predictions results\n",
       "33        24           24    True\n",
       "34      1793         1793    True\n",
       "35      1793         1793    True\n",
       "37      1793         1793    True\n",
       "101     1793         1793    True\n",
       "102     1793         1793    True\n",
       "105     1793         1793    True\n",
       "217     1793           24   False\n",
       "261     1793         1793    True\n",
       "295     1793         1793    True\n",
       "354     1793         1793    True\n",
       "355     1793         1793    True\n",
       "399     1793         1793    True\n",
       "474     1793         1793    True\n",
       "507     1793         1793    True\n",
       "545     1793         1793    True\n",
       "554       24           24    True\n",
       "604       24           24    True\n",
       "607       24          368   False\n",
       "608       24           24    True\n",
       "662       24         1793   False\n",
       "686     1793         1793    True\n",
       "710     1793         1793    True\n",
       "860       24           24    True\n",
       "861       24          368   False\n",
       "862       24         1793   False\n",
       "863       24           24    True\n",
       "864       24           24    True\n",
       "865       24           24    True\n",
       "866       24           24    True\n",
       "...      ...          ...     ...\n",
       "9704    1793         1793    True\n",
       "9715    1793         1793    True\n",
       "9716    1793         1793    True\n",
       "9718    1793           24   False\n",
       "9719    1793           24   False\n",
       "9720    1793         1793    True\n",
       "9724    1793         1793    True\n",
       "9726    1793         1793    True\n",
       "9727    1793         1793    True\n",
       "9729    1793          368   False\n",
       "9730    1793         1793    True\n",
       "9731    1793           24   False\n",
       "9732      24           24    True\n",
       "9734      24           24    True\n",
       "9735    1793         1793    True\n",
       "9739      24           24    True\n",
       "9740      24           24    True\n",
       "9744      24         1793   False\n",
       "9746      24           24    True\n",
       "9749      24           24    True\n",
       "9750      24           24    True\n",
       "9751      24           24    True\n",
       "9752      24           24    True\n",
       "9753      24           24    True\n",
       "9754      24           24    True\n",
       "9755      24           24    True\n",
       "9756      24           24    True\n",
       "9757      24         1793   False\n",
       "9758      24           24    True\n",
       "9759      24         1793   False\n",
       "\n",
       "[1011 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df = fns.result_table(extrc_true, extrc_pred)\n",
    "test_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "================================================================================================================\n",
    "\n",
    "# PCA + Extra Tree\n",
    "\n",
    "================================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Get 15 principal components\n",
    "pca = PCA(n_components=15)\n",
    "pca.fit(train)\n",
    "pca_transformed = pca.transform(train)\n",
    "\n",
    "pca_transformed_test = pca.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96475902243110068"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEZCAYAAACJjGL9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XecnGW5//HPl4RAGi30EHqH0I2RIgtECEQI6KErIAg5\nRxELKiBqgnqO7acCVlRERJAmQghRQltAeihJgAQSMKRBpJMghCR7/f64nyGTZXd2dndmn5nd7/v1\nmtfMU+ea2dm55r6fuygiMDMza80qeQdgZma1zYnCzMxKcqIwM7OSnCjMzKwkJwozMyvJicLMzEpy\norCqkXSKpHvzjqPSJG0qaZEkdfI8v5b0zQrEs7mkJkn+f7aq8AerjkjaV9L9kt6Q9Kqkf0raK+eY\nxklamn1xvi7pPknDO3CeRkmntfOY30qaIWm5pJNb2P5lSS9KelPSpZL6lDhXk6TF2euYJ+knrX3x\nRsSciBgYneyEFBH/ExHf68w5yiXpBEmTs9e3QNJESft0xXPXguzvu2XecdQrJ4o6IWkNYAJwEbA2\nMBi4AFjSzvP0rnBoAfwlIgYC6wH/BG7o4Hna6wngc8BjzY+XdAhwDnAgsBmwJen9KmWX7HUcBJwA\nnN58hyq8f1Un6SvAz4DvAesDQ4BfAkfkGVcOOlUC7NEiwrc6uAF7Aa+3sc/pwNPAW8BTwG7Z+tnA\n14GpwDukHwjDgfuB10lfuPsXnWdN4FJgATAP+C6wSivPOQ64omh5J6AJWAc4Bbi3aNvewCPAG8DD\nwEey9f8LLMtiWwRc3M735l7gpGbrrgK+V7R8APBiiXM0AVsWLV8LXExKMk3AqcALQGPRulWyfRuB\n75CS5FvArcCgonPtW/RezynECvwR+G72uCF7r88DXgb+BZxQdI5RwOPAm9k5xhZt27w4nmava83s\nPf1kide+GnAhMD+7/Qzo0yyurwH/zj4TRwKHAc8CrwLnNvs8XA9cnb0Xj5IScGH7Dtn79TrwJHB4\n0bY/khLYhOzYB5v9TbYHbsuecwZwdDnHAvdk78/i7L04Glg32/f17Hz3AMr7/7xWb7kH4FuZfygY\nCLyS/UOMBNZutv3o7B96z2x5K2DT7PFs0q/uwdmXwuDsXCOz7SOy5UHZ8t+AXwN9SaWEh4AzWolr\nHFmiyM79Y2B2tnwKWaIgJY7XgRNJieo44LXC6wDuAk5tdu6bga+X8d60lCieaPZFMij7sli7lXM0\nAVtlj3cEXgQ+w4qk8Mfs/ViNZl/M2RffTGBrYPXstXw/27ZZ9sV1LNArex92zbZdBnwne9wALAX+\nH7Aq8NHsi23bbPv+wE7Z46HAS8DobHmleJq9rpHZeVtM9Nk+3yElsnWz230txPXNLP7PZp+VK4H+\n2Xv1H2Czos/De8Ansv3PBp7PHq8KzALOBXqTkvdbRa/xj9m598r2/zOptEr2XHOBk7PPz26khLpD\nW8cW/X2Lk873SZ/xXtltn7z/x2v55qqnOhERi0i/TAP4HfBvSTdJWj/b5bPADyPi0Wz/5yJiTuFw\n0q/0+RGxBPgUMDEi/pHtezswGRglaQPgUODLEfFORLxM+rV5XInwjpFU+LW8O3BUC/uMAp6JiCsj\noikirib9Kiyu/lipaiAiDo+IH5Xx9rRkAOnXd8Fb2f3AEsc8Juk1YDzwu4i4rCimcdn70VJVXwCX\nRcSsiHiXVBrZLdt2AnBbRFwTEcsj4rWImFJ0bPPqkG9FxNKIuAe4BTgGICLujoinssfTSL/Y9y/x\nWgoGAa9ERFOJfU4gJYZXIuIVUhXdp4u2LwX+NyKWA9eQkt2FEfF2RDxNKsXuWrT/5Ii4Idv/p6Tk\n+RFSKbZ/RPwgIpZFxF2kX/XHFx17Q0RMzo69khXv48eBf0XE5dnn5wlSFefRZRzbkveAjYDNs7/L\nfSX27fHqrr61J4uIGaRfuUjajvSr6ULSP/omwHMlDp9b9Hgz4GhJhxet6w3cCWxK+uX3YlGjnlVI\nSaA110TESW2Ev3EL53ghW19QyREqFwNrFC2vmd0vKnHM7hHxfCvb5rayvuClosfvkBIVpOsBrZ2z\nudcj4p2i5fffH0kfBn5AqtrrQyrZXFvGOV8F1pW0SolksXH2XAVzWPnv8mpEFP42hfgWFm0vfr2Q\nSrYARERImld0vubvY/FnIEqcdzPgw9kPkoLewJ/KOLYlPyaVfiZln/PfRsQPS+zfo7lEUaci4hng\ncmDnbNVcUtVHq4cUPZ5Dqi5au+g2MPv1Po90gXxQ0bY1I2JoifOWc5FwPumfvdhm2frm8VXCU6z8\ni3JXYGFEvN7K/m3paHxzSNWA5Zx3bUn9ipaL35+rgBuBTSJiLeA3lPf/+wDp79lSKa9gAan6qmDT\nbF1HDSk8yFqObUJ6HQuAIc2aFRe/xlLmAHe38Jn9fEcCjIjFEfHViNiKVKr9iqQDO3KunsCJok5I\n2k7SVyQNzpaHkIrsD2S7/B74qqQ9lGwtadNWTvdn4HBJB0vqJWl1SQ2SBkfEi8Ak4KeSBkpaRdJW\nkj7aWmhlvoS/A9tKOl5Sb0nHki5OTsi2L6T0F+oHn1haVdLqpM9xn+x1FOL5E3CapB0krQ18i3RN\noFpaex+uAkZIOjp73YMk7Vp0TPPjLshe136k6rrrsvUDSCWO9yQNI5Ui20xeEfEm8G3gl5JGS+qX\nnf9QSYVf0H8BvilpXUnrZvtfUebrbsmeko7KWoh9CXiXdHH5YdL1jK9nMTSQqpSuzo4r9Vm6hfT5\n+VR27KqSPiRp+zKOhWafL0mjsv8Rkaoll2c3a4ETRf1YBHwYeEjSYlKCmEq6WEhEXE9qPXQV6YN/\nA6kZ7QdExDxgNPANUkuWOdl5Cp+Hk0jVG0+TLjhfB2zYSlxB619Y72+LiFdJXwpnky46fhX4eES8\nlu17EfBfkl6TdCFA1tb/3FbfkdQC5j+kuu/fZo/3y57vVuBHpAvLs0nVcmNLnKvUl25L25qvi2aP\nC697DqmF0NmkaqDHgV2a75d5iXTBfwHpi3pMRDybbfsc8B1Jb5GS3jXlxh8RPwW+QrogXfh7f47U\naAFSs9nJpM/T1Oxxcf+OUq/1A08H3ES6eP8aqfHCJ7LrAO8Bh5Ougb0M/AL4dNFrbOmzVHgfFwEH\nk66VzSc1Nvg+6XNa8tjMOODyrK/P0cA2pM/PItKF/F9GxN0lXlePphVVj1U4uTSSVIfeC/h98zpA\nSaNJLS6astvXIuLOco41606yX9dXRMSQtvatZZLGAltHxKfb3NnqRtUuZkvqRfrFMIL0C+ARSeMj\nYnrRbrdHxE3Z/kNJv3C2LvNYM6s97tTWDVWz6mkYMCsiZkfEUlI95OjiHSLi7aLFAaQqibKONeuG\nusO8xKWqIq1OVbN57GBWbgo3j1THvhJJR5LqGjci1UGWfaxZdxERjaTWRnUtItoaJsXqUDVLFGX9\nqoiIGyNiB9JFriuaNZ0zM7OcVbNEMZ+i9tTZ43mt7EtE3Js1p1sn26/NYyW5iGtm1gERUfaP8mqW\nKCYD2yiNld+H1FxufPEOWft8ZY/3gPebUbZ5bEG5Y5XU4m3s2LG5x+D484+jJ8Zfz7F3h/jbq2ol\niohYJulM0kiavYBLI2K6pDHZ9kuATwInSVpKGnLhuFLHVitWMzNrXVXHeoqIv5N65Bavu6To8Y9I\nnaLKOtbMzLqee2bnqKGhIe8QOsXx56ue46/n2KH+42+vqvbMrjZJUc/xm5nlQRJRIxezu4TzhJlZ\nddV9onjiibwjMDPr3uo+Udx0U94RmJl1b04UZmZWUt0ninnz4IUX2t7PzMw6pu4TxahRLlWYmVVT\n3SeKI490ojAzq6a670exeHGw0Uap+mntFif+NDOzYj2uH0X//tDQABMn5h2JmVn3VPeJAmD0aFc/\nmZlVS91XPUUECxfCdtvBwoWw2mp5R2VmVtt6XNUTwAYbwE47wZ135h2JmVn30y0SBbj1k5lZtXSL\nqieAZ59NF7XnzYNVuk36MzOrvB5Z9QSw7baw5poweXLekZiZdS/dJlGAWz+ZmVVDt0sUN96YdxRm\nZt1Lt0oUH/4wvPoqzJqVdyRmZt1Ht0oUq6wCRxzh6iczs0rqVokCfJ3CzKzSuk3z2IJ3300d8J57\nDtZdN6fAzMxqWI9tHluw+uowYgRMmJB3JGZm3UO3SxTg1k9mZpXU7aqeILV82mILeOkl6Ncvh8DM\nzGpYj696Ahg0CPbcE26/Pe9IzMzqX7dMFODWT2ZmlVLVRCFppKQZkmZKOqeF7SdKmiJpqqT7JO1S\ntG12tv5xSQ+397lHj4abb4blyzv7KszMeraqJQpJvYBfACOBHYHjJe3QbLfngY9GxC7Ad4HfFm0L\noCEido+IYe19/i22gA03hAce6Fj8ZmaWVLNEMQyYFRGzI2IpcDUwuniHiHggIt7MFh8CNml2jrIv\ntrTEc1SYmXVeNRPFYGBu0fK8bF1rTgMmFi0HcLukyZJO70gAhesUddywy8wsd72reO6yv54lHQCc\nCuxTtHqfiHhR0nrAbZJmRMS97Qlgjz3gnXdgxgzYoXmll5mZlaWaiWI+MKRoeQipVLGS7AL274CR\nEfF6YX1EvJjdvyzpb6SqrA8kinHjxr3/uKGhgYaGhqJzrxgk0InCzHqqxsZGGhsbO3x81TrcSeoN\nPAMcBCwAHgaOj4jpRftsCtwJfCoiHixa3w/oFRGLJPUHJgEXRMSkZs/RYoe7YpMmwdixvqhtZlbQ\n3g53VStRRMQySWcCtwK9gEsjYrqkMdn2S4BvA2sDv5YEsDRr4bQhcEO2rjdwZfMkUa6GhlT19OKL\nsNFGnX1VZmY9T7ccwqO544+HAw6AM87ogqDMzGqch/BogXtpm5l1XI8oUbz5JgwZAgsWwIABXRCY\nmVkNc4miBWuuCcOHw6235h2JmVn96RGJAjxHhZlZR/WIqieAuXNht93SHBWrrlrlwMzMapirnlox\nZEgaKPCf/8w7EjOz+tJjEgW49ZOZWUf0yERRx7VtZmZdrkcliqFD0/3UqfnGYWZWT3pUopBc/WRm\n1l49KlGAJzMyM2uvshKFpM0ljcge95O0RnXDqp5994UXXkjNZc3MrG1tJgpJZwDXAZdkqzYB/lbN\noKqpd2847DAYPz7vSMzM6kM5JYrPA/sCbwFExLPA+tUMqtp8ncLMrHzlJIolEbGksJBNSFTXDUwP\nOSRNZPTGG3lHYmZW+8pJFHdLOh/oJ+ljpGqom6sbVnUNGAD77w9//3vekZiZ1b5yEsW5wMvANGAM\nMBH4ZjWD6gqufjIzK0+bgwJmc1a/GxHLs+VewGoR8Z8uiK+k9gwK2NxLL8EOO8DChdCnT4UDMzOr\nYdUYFPBOoG/Rcj/g9vYGVms23BC23x4aG/OOxMystpWTKFaLiMWFhYhYREoWdc9zVJiZta2cRPG2\npD0LC5L2At6pXkhdZ/To1J/CgwSambWudxn7fAm4VtKL2fJGwLHVC6nrbL899O8Pjz4Ke+2VdzRm\nZrWpzUQREY9I2gHYjtR/4pmIWFr1yLpA8SCBThRmZi0raypUSXsDW5ASSwBExJ+qG1rbOtPqqeC+\n++B//sdDj5tZz9HeVk/lNI/9M7Al8ASwvLA+Ir7Q0SArpRKJYvly2Hjj1FN7yy0rFJiZWQ2rRqKY\nDuzY6W/kKqhEogA47TTYeWf48pcrEJSZWY2rRj+KJ0kXsLstz1FhZta6ckoUjcBuwMNAYXDAiIgj\nqhta2ypVonjnndQB7/nnYdCgCgRmZlbD2luiKKd57LiOh1Mf+vaFAw+EW26Bk07KOxozs9rSZtVT\nRDS2dCvn5JJGSpohaaakc1rYfqKkKZKmSrpP0i7lHltpHiTQzKxl5VQ9fQS4GNgBWA3oBSyOiJLT\noWaDBz4DjADmA48Ax0fE9Gbnfjoi3pQ0EhgXEcPLOTY7vmLX2F95BbbaKg0W2Ldv2/ubmdWralzM\n/gVwAjATWB04DfhVGccNA2ZFxOysg97VwOjiHSLigYh4M1t8iDTNalnHVtq668Kuu8Idd1TzWczM\n6k85iYKImAn0iojlEXEZMLKMwwYDc4uW52XrWnMaaa6LjhxbEW79ZGb2QeVczH5b0mrAFEk/Al4C\nyimylF0nJOkA4FRgn/YeO27cuPcfNzQ00NDQUO6hHzB6NPzoR9DUBKuUlULNzGpfY2MjjZ2YU6Gc\naxSbAwuBPsCXgTWAX0XErDaOG0665jAyWz4PaIqIHzbbbxfgBmBk4ZztOLbi/QB33hl+9zv4yEcq\nelozs5pR8Z7ZnQikN+mC9EHAAlI/jOYXszclTYz0qYh4sD3HZvtVPFGcf34a1uMHP6joac3MakbF\nLmZLui67f1LStGa3NofQi4hlwJnArcDTwDURMV3SGEljst2+DawN/FrS45IeLnVsuS+qMzyZkZnZ\nylotUUjaOCIWSNqMFq5JRMTsKsfWpmqUKJqaYMgQuPNO2G67ip7azKwmVKxEkSWJ3sAfs2aqK90q\nEWwtWmUVOOIIt34yMyso2bYnqwJqkrRWF8VTE9xL28xshXJaPY0HdgcmAf/JVkdEnFXl2NpUjaon\ngCVLYIMN4Jln0r2ZWXdSjUEBb8huxWpubopKWm01OPhguPlm+Oxn847GzCxfVWse2xWqVaIA+Mtf\n4IorYOLEtvc1M6sn1Zjhblvg/4AdgcJweRERuU8cWs1EsWgRbLIJzJ4Na69dlacwM8tFNQYFvAz4\nDbAMaAAuB67sUHR1ZOBAGDEC/va3vCMxM8tXOYmib0TcTip9vBAR44BR1Q2rNhxzDFx7bd5RmJnl\nq5xE8W42P8QsSWdK+gTQv8px1YRRo+CBB+DVV/OOxMwsP6WG8Ngwe/hFoB9wFrAX8Cng5OqHlr8B\nA1LrJ1c/mVlPVqpEMUXS7cAupLko5kbEKRHxieIB/Lq7Y4+Fa67JOwozs/yUGuupN2kq0uOAQ4EH\ngb8AN0XEO10WYQnVbPVU8J//wEYbwaxZsN56VX0qM7MuUcmxnpZFxD8i4hRgU1Lrp9HAvyRd1elI\n60S/fnDooXBD8y6HZmY9RLlToS4hDfc9HVgE7FDNoGrNsce69ZOZ9VwlO9xlEwsdl90GkKqe/hIR\nM7omvNK6ouoJ4J13UvWTx34ys+6gkhMX3Q/8E1gfOD0ito2IsbWSJLpS376pqexf/5p3JGZmXa/U\nxez9gXsjoqlrQypfV5UoIA07/rOfQSfmJzczqwk1M2d2V+jKRPHuu6n66amnYOONu+Qpzcyqohpj\nPRmw+upw+OGufjKznseJoh089pOZ9USlrlGcXbQYgIoeExE/rW5obevKqieA996DDTeEadNg8OAu\ne1ozs4qqZNXTQFKT2D2B/wE2BgYD/w3s0Zkg61WfPmk+7euuyzsSM7OuU87ERfcCh0XEomx5IDAx\nIvbrgvhK6uoSBcDf/w7f/S7cf3+XPq2ZWcVU42L2+sDSouWl2boe6aCDUse7OXPyjsTMrGuUkyj+\nBDwsaZykC4CHSLPc9Uh9+sBRR7n6ycx6jrL6UUjaE9g3W7wnIh6valRlyqPqCWDSJPjWt+Chh7r8\nqc3MOq1a/Sj6AYsi4iJgnqQtOhRdN3HAAfD88zB7dt6RmJlVX5uJQtI44OvAudmqPsCfqxhTzVt1\nVVc/mVnPUU6J4ijSPBRvA0TEfFLT2TZJGilphqSZks5pYfv2kh6Q9G6zfhtImi1pqqTHJT1czvN1\nJc98Z2Y9Re8y9lkSEU1Sqs6S1L+cE0vqBfyCNEvefOARSeMjYnrRbq8CXwCObOEUATRExGvlPF9X\n23//1PLpuedgq63yjsbMrHrKKVFcJ+kSYC1JZwB3AL8v47hhwKyImB0RS4GrSSWT90XEyxExmZWb\n3xYr+2JLV+vdGz75SVc/mVn312aiiIgfA3/NbtsC34qIi8s492BgbtHyvGxduQK4XdJkSae347gu\n45nvzKwnKKfqiYiYBExq57k72251n4h4UdJ6wG2SZkTEvc13Gjdu3PuPGxoaaGho6OTTlm+//WDB\nApg5E7bZpsue1sysXRobG2nsxGQ65Qzh8UngB8AGFA0MGBFrtHHccGBcRIzMls8DmiLihy3sOxZY\nHBE/aeVcLW7Pqx9FsTPPTPNUnH9+rmGYmZWtGv0ofgQcERFrRMTA7FYySWQmA9tI2lxSH+BYYHwr\n+64UsKR+2ZhShYvnBwPTynjOLuehx82suyun6umlZi2VyhIRyySdCdwK9AIujYjpksZk2y+RtCHw\nCLAG0CTpi8COpLGkbshaWvUGrsyqv2rOvvvCK6/AjBmw/fZ5R2NmVnnlVD1dBGwI3Ai8l62OiLih\nyrG1qRaqngC++EUYNAi+/e28IzEza1vF58yW9Mfs4Uo7RsRn2h1dhdVKorjvPhgzBp58Mu9IzMza\nVvFEUctqJVE0NcFmm8E//gE77ZR3NGZmpVUsUUg6JyJ+KOnnLWyOiDiro0FWSq0kCoCvfAUGDoQL\nLsg7EjOz0irZ6unp7P5RUgumR5vdrEih9VON5C0zs4px1VOFRMDmm8OECTB0aN7RmJm1rr0lijab\nx0panzTM+I5A32x1RMSBHQuxe5JWlCqcKMysOymnw92VwAxgS2AcMJtUFWXNHHNMGnq8Rgo5ZmYV\nUU6iGBQRvwfei4i7s2axLk20YK+9YOlSmDIl70jMzCqnnERR6GT3kqSPS9oDWLuKMdWt4uonM7Pu\nopwOd4cD9wJDgJ+ThtsYFxGtjdvUZWrpYnbBY4/B0UfDrFkpcZiZ1Rp3uMtZRBpy/JprYM89847G\nzOyDKtbqqZWOdgU10eGuFhVXPzlRmFl3UKpn9imsGN+peeaJiLi8inGVpRZLFJAuZh95JDz/vKuf\nzKz2VK3qSdKapImHFnU0uEqr1UQRkYYcv+IKGDYs72jMzFZW8YmLJH1I0jRgKvCkpCmS9upMkN2d\nWz+ZWXdSTqunacDnCvNVS9oX+FVE7NIF8ZVUqyUKgGnTYNQoeOEFVz+ZWW2pxlSoywpJAiAi/gks\n60hwPcnOO8OAAfDgg3lHYmbWOeUkirslXSKpIbv9Olu3R9b5zlrg6icz6y7KqXpqpNnsdsUi4oAK\nx1S2Wq56AnjqKTjkEJgzB1YpJyWbmXWBio8eGxENnYqoB9tpJ1hrLXjgAdhnn7yjMTPrmHJaPf1Z\n0lpFy5tLurO6YXUfxx6bemmbmdWrcipE7gUekjRK0hnAJOBn1Q2r+zj6aLj+eli+PO9IzMw6ppyq\np0skPQ3cCbwC7BERL1Y9sm5i++1hvfXgvvvgox/NOxozs/Yrp+rp08AfgJOAPwITJe1W5bi6lWOP\ndesnM6tf5bR6uhE4IyL+nS0PA34bEbkni1pv9VQwcybstx/Mnw+9euUdjZn1dBXvcBcRRxaSRLb8\nMOARjNphm21g443hnnvyjsTMrP1aTRSSri16/MNmmydULaJuyp3vzKxelSpRbFP0+OBm29arQizd\n2jHHwF//Css8+ImZ1Zmq9heWNFLSDEkzJZ3TwvbtJT0g6V1JZ7fn2Hqz5Zaw2WbQ2Jh3JGZm7VOq\neWzfbCwnFT2msNzWiSX1An4BjADmA49IGh8R04t2exX4AnBkB46tO4XqpxEj8o7EzKx8pRLFS8BP\nWngMUE4/imHArIiYDSDpamA08P6XfUS8DLwsaVR7j61HxxwDe+0Fv/wlrLpq3tGYmZWn1URRgTGe\nBgNzi5bnAR/ugmNr1mabwVZbwZ13psECzczqQZs9szuhMx0cyj523Lhx7z9uaGigoaGhE09bfYXq\nJycKM+sqjY2NNHbiAmnZc2a3+8TScGBcRIzMls8jzbndvKktksYCiyPiJ+05tl463BWbOxd22w1e\nfBH69Mk7GjPriSrW4U7SPtn96h2MZTKwTTbabB/gWGB8a0/XiWPrypAhafynO+7IOxIzs/KUah57\ncXb/QEdOHBHLgDOBW4GngWsiYrqkMZLGAEjaUNJc4MvANyXNkTSgtWM7EkctOuYYDz1uZvWj1aon\nSQ8BU0mtja5m5V/9ERFnVT+80uqx6gnSmE9Dh6bqp9VWyzsaM+tpKjnW08eBO4B3gEdbuFkHDR6c\nZr+79lrPU2Fmta+c0WN3i4gnuiiedqnXEgXATTfBV74CCxfCzjunC9yF29Ch0L9/3hGaWXfV3hJF\nOYliCOl6xb7ZqnuAL0bEvA5HWSH1nCgK3nwTpk6FJ55YcZs+HTbddOXksdtusOGGeUdrZt1BNRLF\n7cCVwJ+zVScCJ0bExzocZYV0h0TRkqVLYcaMlZPH44+n5rS77Qa7774ieWy9tee4MLP2qUaimBIR\nu7a1Lg/dNVG0JALmzVs5eTzxRKq6Gjr0g1VX/frlHbGZ1apqJIo7gcuAq0gtn44DPhMRB3Um0Ero\nSYmiNYWqq8cfX5E8ZsxIw4WcdBJ89aseV8rMVlaNRLE58HNgeLbqfuALETGngzFWjBNFy957D558\nEs47D155BS67DHbZJe+ozKxWVDxR1DInitIi4A9/gHPPhbPOSvcuXZiZE4V9wNy5cMYZ6XrGZZfB\nrrlfXTKzPFWyw511E0OGwMSJqVTxsY/BBRek6ikzs3I4UfQQEpxySrro/cgjMGxYemxm1payE4Wk\n4ZL+IeluSUdVMyirnsGD4eabU6/wQw6Bb3/bpQszK63UoIAbRsRLRcvXASdniw9HxM5dEF9JvkbR\nOQsWwH//N8yena5d7Lln3hGZWVeo5DWK30j6dtF8FG8AnwQ+AbzZiRitRmy8cRpz6pxz4LDD4Jvf\nhCVL8o7KzGpNq4kiIo4EHgcmSDoJ+BKwOrAOcGTXhGfVJsGJJ6aOek8+mUoVkyfnHZWZ1ZJyOtz1\nAj5PGnb8exFxT1cEVg5XPVVWBFx9NXzpS3DqqTB2LKze0fkNzaxmVXIq1NGS7iLNMjeNNB3pkZKu\nlrRV50O1WiPB8cenIUGefRb22AMeeijvqMwsb6UuZk8DhpGqmyZFxIey9duQShbHdlmUrXCJonoi\n4LrrUt+Lk09OfS9cujDrHip5MftN4Cjgv4CFhZURMbMWkoRVl5Tm9p46Ff71rzS0+YMP5h2VmeWh\nVKI4ClhUV+AoAAAP50lEQVQX6AWc0DXhWK1Zf/00Zet3vgNHHQVf+xq8807eUZlZV/JYT1a2l19O\nVVGPPZb6Xey9d94RmVlHeFBAq7obboAzz4T11kt9MVq7bbAB9O6dd7Rm1pwThXWJt9+GmTNT7+7W\nbq+8AoMGrZw8Bg/+YEJZd11YxaOOmXUZJwqrGcuWwb//XTqZLFiQZunbYIMPJpTjjoMttsj7VZh1\nP04UVneWLIGXXlo5ecyaBVdeCV/4Anz969C3b95RmnUfThTWbcyZk0a5fewxuPhi+PjH847IrHtw\norBuZ9KkVLLYdlu46CLYcsu8IzKrb57hzrqdgw9OHf/22SdNuDR2rPtymHWlqiYKSSMlzZA0U9I5\nrexzcbZ9iqTdi9bPljRV0uOSHq5mnFb7VlsNzj03zco3fTrsuCOMH5+GGjGz6qpa1VM26uwzwAhg\nPvAIcHxETC/a5zDgzIg4TNKHgYsiYni27V/AnhHxWonncNVTD3X77akvx1ZbpeqorbfOOyKz+lFL\nVU/DgFkRMTsilgJXA6Ob7XMEcDlARDwErCVpg6LtZb8Q61lGjEjVUfvvD8OHw7e+Bf/5T95RmXVP\n1UwUg4G5RcvzsnXl7hPA7ZImSzq9alFa3erTJzWdfeKJ1Plvp53gxhtdHWVWadVMFOX+u7ZWatg3\nInYHDgU+L2m/yoRl3c0mm6QJly69FL7xjTSt68yZeUdl1n1UcySe+cCQouUhpBJDqX02ydYREQuy\n+5cl/Y1UlXVv8ycZN27c+48bGhpoaGjofORWlw48MJUuLr4YPvIRGDMmJY7+/fOOzCxfjY2NNDY2\ndvj4al7M7k26mH0QsAB4mNIXs4cDF0bEcEn9gF4RsUhSf2AScEFETGr2HL6YbS2aPz8NiX7fffCz\nn6Uh0uUrXmZAjXW4k3QocCFpTotLI+L7ksYARMQl2T6/AEYCbwOfiYjHJG0J3JCdpjdwZUR8v4Xz\nO1FYSY2N8PnPp+qpn/88ddoz6+lqKlFUmxOFlWPp0pQk/u//4Iwz4PzzXR1lPVstNY81qwmrrprG\njJo2LY0ftcMOcP310NSUd2Rm9cElCutx7r4bzj4b5s2DUaPSYIMf+xgMGJB3ZGZdw1VPZmV6/nm4\n5Ra4+WZ48MHUUurww1Pi2HzzvKMzqx4nCrMOWLQIbrstJY1bboH111+RNIYPh1698o7QrHKcKMw6\nqakJHnkkJY0JE1JT20MPTUnjkENgzTXzjtCsc5wozCpszpxUypgwAe69F/baa0VpY5tt8o7OrP2c\nKMyq6O234Y47UtKYMAEGDlyRNPbZJ7WwMqt1ThRmXaSpKc2PMWFCqqZ67rlUNXX44TByJAwalHeE\nZi1zojDLyYIFMHFiShp33pkuiO+4YxrVtnDbfnvo1y/vSK2nc6IwqwHLlqUSxlNPwdNPp/unnkqj\n2m688YrEUUgkTiDWlZwozGpYcQIp3J5+OiWQwYNbLoH07Zt31NbdOFGY1aFly2DWrA+WQGbNSgmk\nOHnsuKMTiHWOE4VZN7J0acslkOefh733htGj023IkLbPZVbgRGHWA7z9NkyalKZ+veUW2GyzlDCO\nPBKGDvXcG1aaE4VZD7NsGfzzn3DTTekWsSJp7Lsv9K7mPJZWl5wozHqwiDSc+k03pdLGCy+kEXJH\nj059PDwPh4EThZkVmTsXxo9PSeOhh2D//VPSOPxw2GCDvKOzvDhRmFmL3ngD/v73lDRuvTW1oDry\nyJQ4PEVsz+JEYWZtWrIE7rorVVGNHw9rrLEiaQwbBqt47stuzYnCzNqlqQkmT15xXeO119L1jI02\ngnXWSbe11/7gff/+bl1Vr5wozKxTZs1KY1W9/HJKGq+/vuK++PHSpS0nkLbu114b+vTJ+1X2bE4U\nZtYllixZOXGUe//66ylRDByY5ikv3BduxculthUv9+vn0k17OFGYWU2LSB0GFy9OU9AuXrziVrzc\nnm3vvpuSRSFx9O8Pq6/e+m211Upvb2u//v3T89TrtRwnCjPrcZYvXzn5vP12Sh5LlqT7tm7l7lfY\nd/FieOed1AhgrbVSddpaa33wcaltffvmVwpqb6Jwn00zq3u9eqUv7TXW6LrnXLYM3nwzNTt+/fV0\n3/zxiy+2vq2pqfXkMmBAmi2xd+90Kzyu1H17uURhZpaDd99tOYG88UYqsSxblhoMFN+3tK4j9889\n56onMzMrob1VT3V6KcbMzLpKVROFpJGSZkiaKemcVva5ONs+RdLu7TnWzMyqr2qJQlIv4BfASGBH\n4HhJOzTb5zBg64jYBjgD+HW5x3YHjY2NeYfQKY4/X/Ucfz3HDvUff3tVs0QxDJgVEbMjYilwNTC6\n2T5HAJcDRMRDwFqSNizz2LpX7x82x5+veo6/nmOH+o+/vaqZKAYDc4uW52Xrytln4zKONTOzLlDN\nRFFucyR3vDczq2FVax4raTgwLiJGZsvnAU0R8cOifX4DNEbE1dnyDGB/YIu2js3Wu22smVkH1ErP\n7MnANpI2BxYAxwLHN9tnPHAmcHWWWN6IiIWSXi3j2Ha9UDMz65iqJYqIWCbpTOBWoBdwaURMlzQm\n235JREyUdJikWcDbwGdKHVutWM3MrHV13TPbzMyqr257ZtdzhzxJQyTdJekpSU9KOivvmNpLUi9J\nj0u6Oe9Y2kvSWpKulzRd0tNZtWfdkHRe9tmZJukqSavlHVMpkv4gaaGkaUXr1pF0m6RnJU2StFae\nMZbSSvw/zj4/UyTdIGnNPGMspaX4i7adLalJ0jqlzlGXiaIbdMhbCnw5InYChgOfr7P4Ab4IPE35\nrdtqyUXAxIjYAdgFqJtqzey63enAHhExlFQ1e1yeMZXhMtL/arFzgdsiYlvgjmy5VrUU/yRgp4jY\nFXgWOK/LoypfS/EjaQjwMeCFtk5Ql4mCOu+QFxEvRcQT2ePFpC+qjfONqnySNgEOA35PnTVvzn75\n7RcRf4B0PSwi3sw5rPZ4i/RDo5+k3kA/YH6+IZUWEfcCrzdb/X5n2+z+yC4Nqh1aij8ibouIpmzx\nIWCTLg+sTK28/wA/Bb5ezjnqNVGU05mvLmS/EHcnfdjqxc+ArwFNbe1Yg7YAXpZ0maTHJP1OUr+8\ngypXRLwG/ASYQ2oR+EZE3J5vVB2yQUQszB4vBDbIM5hOOhWYmHcQ7SFpNDAvIqaWs3+9Jop6rO74\nAEkDgOuBL2Yli5on6ePAvyPiceqsNJHpDewB/Coi9iC1tqvlao+VSNoK+BKwOakUOkDSibkG1UnZ\nXAF1+T8t6XzgvYi4Ku9YypX9MPoGMLZ4dalj6jVRzAeGFC0PIZUq6oakVYG/An+OiBvzjqcd9gaO\nkPQv4C/AgZL+lHNM7TGP9EvqkWz5elLiqBd7AfdHxKsRsQy4gfQ3qTcLs3HdkLQR8O+c42k3SaeQ\nqmDrLVFvRfqhMSX7P94EeFTS+q0dUK+J4v3OfJL6kDrkjc85prJJEnAp8HREXJh3PO0REd+IiCER\nsQXpIuqdEXFS3nGVKyJeAuZK2jZbNQJ4KseQ2msGMFxS3+xzNILUqKDejAdOzh6fDNTTjyUkjSRV\nv46OiHfzjqc9ImJaRGwQEVtk/8fzSI0jWk3WdZkosl9ShQ55TwPX1FmHvH2ATwEHZE1MH88+ePWo\nHqsMvgBcKWkKqdXT/+UcT9kiYgrwJ9KPpUL98m/zi6htkv4C3A9sJ2mupM8APwA+JulZ4MBsuSa1\nEP+pwM+BAcBt2f/vr3INsoSi+Lctev+Ltfk/7A53ZmZWUl2WKMzMrOs4UZiZWUlOFGZmVpIThZmZ\nleREYWZmJTlRmJlZSU4U1uWyYY3/X9HyVyWNLXVMO879R0mfrMS52nieo7Mhyu9oYdu2kiZmQ2g/\nKumaUr1e64Gk0XU4wrFViBOF5eE94ChJg7LlSnbm6fC5stFYy3Ua8NmIOKjZOVYHJgC/jIhtI2JP\n4FfAeh2Nq0YcRRrS33ogJwrLw1JSb+IvN9/QvEQgaXF23yDpbkk3SnpO0g8kfVrSw5KmStqy6DQj\nJD0i6RlJo7Lje2WTzTycTTZzRtF575V0Ey0M5SHp+Oz80yT9IFv3bVLv+j9I+lGzQ04gjcV0S2FF\nRNwdEU9JWj0btXZqNnJtQ3a+U7LXNUnSvySdmZWyHpP0gKS1s/0aJV2Y9QSeJulD2fp1suOnZPsP\nzdaPU5q05q7sPftC0ev6lKSHsnP9RtIqhfdb0vckPZGda31JewOHAz/OYtpS0llKkydNyXr+Wjfm\nRGF5+RVwoqQ1mq1vXiIoXt4FGAPsAHwa2CoihpHmxSh8CQrYLCI+BIwCfqM0A9xppCG5h5HmMzld\naYh3SMO8nxUR2xU/saSNSUNLHADsBnxI0uiI+A5pCI0TIqL5eP47AY+28po/DyyPiF2A44HLtWJ2\nup1Iv9o/BPwv8FY2uu0DQGEsrQD6RsTuwOeAP2TrLwAezSbR+QZpiI+CbYGDs9c8NkuYOwDHAHtn\n52pixcB2/YAHImI34B7g9Ii4nzQ201cjYo+IeB44B9gte84xrbxe6yacKCwXEbGI9IXWnmlgH4mI\nhRHxHjCLNNYXwJOk0TAhfZlemz3HLOB5YHvSl+VJkh4HHgTWAbbOjnk4Ilqa5etDwF3ZSK3LgSuB\njxZtb21o5tbW7wP8OYvtGdLMYttmMd8VEW9HxCvAG0BhitlpRa8N0oi9hclo1lCaiGkf4Ips/V3A\nIEkDs/PeEhFLI+JV0gitGwIHAXsCk7P340DSPB2QhswulIYebfbcxa9rKnCV0hDny1t5vdZNtKdO\n1qzSLgQeI03VWLCM7AdMVh3Sp2jbkqLHTUXLTZT+LBdKJWdGxG3FG7Lqn7dLHFf85ShWLuG0dD3k\nKWD/ErG0lkQ6+9paO+97RY+XF53r8oj4Rgv7L20WR/FzF7/eUaSkeThwvqShWTK1bsglCstNRLxO\n+vV/Giu+hGaTfu1Cmi5z1XaeVsDRSrYCtiQNzX0r8LnCBeusZVJbM9s9AuwvaZDSPO3HAXe3ccxV\nwN6SDns/IOmjknYC7iWr4lEa5nzTLLZSk8Y0T1THZsfvS6pKe6vZeRuAl7MSW0vnDdIc1f8lab3s\nmHUkbdrG61oErJHtL2DTiGgkTfq0JtC/jeOtjrlEYXko/mX6E9KQ8QW/A26S9ATwD2BxK8c1P18U\nPZ4DPEz6YhsTEe9J+j2pGuWx7Ivu36RrAq3OrhYRL0o6F7iL9KU7ISJubmnfomPeVZoF8EJJF5J+\noU8Bvki6LvNrSVNJJaeTI2KppOYxNH9c/NrelfQY6X/31Gz9ONKF9Smk0tHJLRxbHON0Sd8EJmWl\ntqWkax5zSjz31cDvsgvixwOXZtVeAi7KEpZ1Ux5m3KxOSLoLODsiHss7FutZXPVkZmYluURhZmYl\nuURhZmYlOVGYmVlJThRmZlaSE4WZmZXkRGFmZiU5UZiZWUn/HxIalXJZkPihAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85f4c2f350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.title(\"Scree Plot: 10 Principal Components\")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"% of Explained Variance\")\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   max_features |   n_estimators | \n",
      "    1 | 00m03s | \u001b[35m   0.64943\u001b[0m | \u001b[32m     7.4445\u001b[0m | \u001b[32m        5.8039\u001b[0m | \u001b[32m      869.1985\u001b[0m | \n",
      "    2 | 00m03s | \u001b[35m   0.66279\u001b[0m | \u001b[32m     9.7668\u001b[0m | \u001b[32m        6.2249\u001b[0m | \u001b[32m      822.4185\u001b[0m | \n",
      "    3 | 00m01s |    0.62741 |      3.3319 |         6.6151 |       452.5464 | \n",
      "    4 | 00m02s |    0.64201 |      5.7320 |         6.7194 |       696.3192 | \n",
      "    5 | 00m02s |    0.64720 |      6.9967 |         5.3167 |       659.5947 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   max_features |   n_estimators | \n",
      "    6 | 00m08s |    0.66230 |     10.0000 |         5.0000 |       100.0000 | \n",
      "    7 | 00m05s |    0.65586 |      9.9376 |         5.0593 |       241.7723 | \n",
      "    8 | 00m04s |    0.60440 |      2.0030 |         6.6616 |       164.8930 | \n",
      "    9 | 00m05s |    0.66106 |      9.9386 |         5.2898 |       338.9477 | \n",
      "   10 | 00m06s |    0.66106 |      9.9478 |         5.2392 |       557.8259 | \n",
      "   11 | 00m05s | \u001b[35m   0.66304\u001b[0m | \u001b[32m     9.9722\u001b[0m | \u001b[32m        6.8382\u001b[0m | \u001b[32m      293.7447\u001b[0m | \n",
      "   12 | 00m07s |    0.66279 |      9.9678 |         5.0239 |       770.5607 | \n",
      "   13 | 00m07s | \u001b[35m   0.66551\u001b[0m | \u001b[32m     9.9890\u001b[0m | \u001b[32m        6.8175\u001b[0m | \u001b[32m      602.2250\u001b[0m | \n",
      "   14 | 00m08s |    0.61331 |      2.0013 |         5.1024 |       795.5165 | \n",
      "   15 | 00m08s |    0.66304 |     10.0000 |         7.0000 |       900.0000 | \n",
      "   16 | 00m06s |    0.66551 |      9.9632 |         6.8089 |       398.2345 | \n",
      "   17 | 00m08s |    0.66551 |      9.9947 |         6.9709 |       505.0898 | \n",
      "   18 | 00m10s |    0.66329 |      9.9965 |         6.8207 |       738.6092 | \n",
      "   19 | 00m10s | \u001b[35m   0.66650\u001b[0m | \u001b[32m     9.9897\u001b[0m | \u001b[32m        6.9487\u001b[0m | \u001b[32m      372.3240\u001b[0m | \n",
      "   20 | 00m12s |    0.66650 |      9.9340 |         6.9114 |       628.3685 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  1.12595349e-05]), 'nit': 5, 'funcalls': 48}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 | 00m12s |    0.65957 |      9.9843 |         5.1479 |       474.2450 | \n",
      "   22 | 00m13s | \u001b[35m   0.66972\u001b[0m | \u001b[32m    10.0000\u001b[0m | \u001b[32m        7.0000\u001b[0m | \u001b[32m      676.5496\u001b[0m | \n",
      "   23 | 00m12s |    0.66502 |      9.9998 |         6.7773 |       429.8514 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -2.28806761e-05]), 'nit': 4, 'funcalls': 49}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 | 00m12s |    0.66625 |      9.9895 |         6.6714 |       527.6679 | \n",
      "   25 | 00m14s |    0.66106 |      9.9802 |         5.1827 |       686.2619 | \n",
      "   26 | 00m15s |    0.66230 |      9.9973 |         6.9656 |       844.8291 | \n",
      "   27 | 00m14s |    0.66378 |      9.9958 |         6.8871 |       784.8735 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-0.00033365]), 'nit': 5, 'funcalls': 52}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 | 00m13s |    0.66403 |      9.9294 |         6.9542 |       268.0828 | \n",
      "   29 | 00m14s |    0.66452 |      9.9809 |         6.9105 |       577.6078 | \n",
      "   30 | 00m13s |    0.66675 |      9.9588 |         6.9457 |       653.6138 | \n",
      "-----------------------------------------------------\n",
      "\n",
      "267.982395\n",
      "Bayesian Optimization Best Score: 0\n",
      "Bayesian Optimization Best Parameters: {'max_features': 7.0, 'n_estimators': 676.54964329047209, 'max_depth': 10.0}\n",
      "{'max_val': 0.66971796140524498, 'max_params': {'max_features': 7.0, 'n_estimators': 676.54964329047209, 'max_depth': 10.0}}\n"
     ]
    }
   ],
   "source": [
    "# Run BO for pca of color histogram\n",
    "extr_bo(extr_pca_evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of best Extra Tree model on train: 0.68654131618\n",
      "Accuracy of best Extra Tree model on test: 0.672601384768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  24, 1793, 1793, ..., 1793,   24, 1793])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the best params from BO results then predict \n",
    "best_estimators = 677\n",
    "best_max_depth = 6\n",
    "best_max_features = 7\n",
    "best_pca_extrc = ExtraTreesClassifier(n_jobs = 4, n_estimators=best_estimators, oob_score=False,\n",
    "                                max_depth = best_max_depth, max_features = best_max_features)\n",
    "\n",
    "best_pca_extrc.fit(pca_transformed, train_labels)\n",
    "\n",
    "# accuracy of trianing dataset\n",
    "print \"Accuracy of best Extra Tree model on train: %s\" % str(best_pca_extrc.score(pca_transformed, train_labels))\n",
    "\n",
    "# accuracy of testing dataset\n",
    "print \"Accuracy of best Extra Tree model on test: %s\" % str(best_pca_extrc.score(pca_transformed_test, test_labels))\n",
    "\n",
    "\n",
    "# use the best params to predict\n",
    "extrc_pca_true, extrc_pca_pred = test_labels, best_pca_extrc.predict(pca_transformed_test)\n",
    "extrc_pca_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68654131618010883"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy of training dataset\n",
    "best_pca_extrc.score(pca_transformed, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67260138476755682"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy of testing dataset\n",
    "best_pca_extrc.score(pca_transformed_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predictions</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>24</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>24</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9715</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9716</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9718</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>1793</td>\n",
       "      <td>368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9720</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9726</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9727</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9729</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9730</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9731</th>\n",
       "      <td>1793</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9732</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9734</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9735</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9746</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9749</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9752</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9753</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9756</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9757</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9758</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9759</th>\n",
       "      <td>24</td>\n",
       "      <td>1793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1011 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual  predictions results\n",
       "33        24           24    True\n",
       "34      1793         1793    True\n",
       "35      1793         1793    True\n",
       "37      1793           24   False\n",
       "101     1793         1793    True\n",
       "102     1793         1793    True\n",
       "105     1793         1793    True\n",
       "217     1793           24   False\n",
       "261     1793         1793    True\n",
       "295     1793         1793    True\n",
       "354     1793           24   False\n",
       "355     1793         1793    True\n",
       "399     1793         1793    True\n",
       "474     1793         1793    True\n",
       "507     1793          368   False\n",
       "545     1793         1793    True\n",
       "554       24           24    True\n",
       "604       24           24    True\n",
       "607       24          368   False\n",
       "608       24           24    True\n",
       "662       24         1793   False\n",
       "686     1793         1793    True\n",
       "710     1793         1793    True\n",
       "860       24          368   False\n",
       "861       24           24    True\n",
       "862       24         1793   False\n",
       "863       24           24    True\n",
       "864       24           24    True\n",
       "865       24           24    True\n",
       "866       24           24    True\n",
       "...      ...          ...     ...\n",
       "9704    1793         1793    True\n",
       "9715    1793         1793    True\n",
       "9716    1793          368   False\n",
       "9718    1793           24   False\n",
       "9719    1793          368   False\n",
       "9720    1793         1793    True\n",
       "9724    1793         1793    True\n",
       "9726    1793         1793    True\n",
       "9727    1793         1793    True\n",
       "9729    1793           24   False\n",
       "9730    1793         1793    True\n",
       "9731    1793           24   False\n",
       "9732      24           24    True\n",
       "9734      24           24    True\n",
       "9735    1793         1793    True\n",
       "9739      24           24    True\n",
       "9740      24           24    True\n",
       "9744      24         1793   False\n",
       "9746      24           24    True\n",
       "9749      24           24    True\n",
       "9750      24           24    True\n",
       "9751      24           24    True\n",
       "9752      24           24    True\n",
       "9753      24           24    True\n",
       "9754      24           24    True\n",
       "9755      24           24    True\n",
       "9756      24           24    True\n",
       "9757      24         1793   False\n",
       "9758      24           24    True\n",
       "9759      24         1793   False\n",
       "\n",
       "[1011 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df = fns.result_table(extrc_pca_true, extrc_pca_pred)\n",
    "test_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
